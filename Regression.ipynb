{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37d2108",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d301aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:16.025666Z",
     "start_time": "2023-01-23T04:03:12.314250Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파이썬 ≥ 3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥ 0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"Regression\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2739ef",
   "metadata": {},
   "source": [
    "# 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc426da",
   "metadata": {},
   "source": [
    "회귀는 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용한 통계적 기법으로, 현대 통계학을 떠받치고 있는 주요 기둥 중 하나다. 어떤 입력 데이터가 들어오면 연속적인 숫자(실수)를 예측하는 것이다. 이 모델을 훈련시키는 두 가지 방법을 설명하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6026c",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>직접 계산할 수 있는 공식을 사용하여 훈련 세트에 가장 잘 맞는 모델 파라미터(즉, 훈련 세트에 대해 비용 함수를 최소화하는 모델 파라미터)를 해석적으로 구한다.</li>\n",
    "    <li>경사 하강법<sup>Gradient Descent</sup>이라 불리는 반복적인 최적화 방식을 사용하여 모델 파라미터를 조금씩 바꾸면서 비용 함수를 훈련 세트에 대해 최소화시킨다. 결국에는 앞의 방법과 동일한 파라미터로 수렴한다. 경사 하강법의 변종으로 배치<sup>batch</sup>경사 하강법, 미니배치<sup>mini-batch</sup> 경사 하강법, 확률적 경사 하강법<sup>Stochastic Gradient Descent</sup>도 살펴보겠다.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfac3bf",
   "metadata": {},
   "source": [
    "회귀는 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법을 통칭한다. 예를 들어 아파타의 방 개수, 방 크기, 주변 학군 등 여러 개의 독립변수에 따라 아파트 가격이라는 종속변수가 어떤 관계를 나타내는지를 모델링하고 예측하는 것이다. $\\mathrm{Y} = \\mathrm{W_1X_1}+ \\mathrm{W_2X_2} + \\cdots + \\mathrm{W_nX_n}$이라는 선형 회귀식을 예로 들면 $Y$는 종속변수, 즉 아파트 가격을 뜻하고 $\\mathrm{X_1, X_2,}\\cdots\\mathrm{,X_n}$은 방 개수, 방 크기, 주변 학군 등의 독립변수를 의미한다. 그리고 $\\mathrm{W_1, W_2,}\\cdots\\mathrm{,W_n}$은 이 독립변수의 값에 영향을 미치는 회귀 계수<sup>Regression coefficients</sup>다. 머신러닝 관점에서 보면 독립변수는 피처에 해당하며 종속변수는 결정 값이다. <mark>머신러닝 회귀 예측의 핵심은 주어진 피처와 결정 값 데이터 기반에서 학습을 통해 <b>최적의 회귀 계수</b>를 찾아내는 것이다.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f6bb8",
   "metadata": {},
   "source": [
    "회귀는 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러 가지 유형으로 나눌 수 있다. 회귀에서 가장 중요한 것은 바로 회귀 계수다. 이 회귀 계수가 선형이냐 아니냐에 따라 선형 회귀와 비선형 회귀로 나눌 수 있다. 그리고 독립변수의 개수가 한 개인지 여러 개인지에 따라 단일 회귀, 다중 회귀로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447f905",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\">독립변수 개수</th>\n",
    "    <th class=\"tg-1wig\">회귀 계수의 결합</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">1개: 단일 회귀</td>\n",
    "    <td class=\"tg-0lax\">선형: 선형 회귀</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">여러 개: 다중 회귀</td>\n",
    "    <td class=\"tg-0lax\">비선형: 비선형 회귀</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350f4ca",
   "metadata": {},
   "source": [
    "여러 가지 회귀 중에서 선형 회귀가 가장 많이 사용된다. 선형 회귀는 실제 값과 예측값의 차이(오류의 제곱 값)를 최소화하는 직선형 회귀선을 최적화하는 방식이다. 선형 회귀 모델은 규제<sup>Regularization</sup> 방법에 따라 다시 별도의 유형으로 나뉠 수 있다. 규제는 일반적인 선형 회귀의 과대적합 문데를 해결하기 위해서 회귀 계수에 페널티 값을 적용하는 것을 말한다. 대표적인 선형 회귀 모델은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50914f",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>일반 선형 회귀:</b> 예측값과 실제 값의 RSS<sup>Residual Sum of Squares</sup>를 최소화할 수 있도록 회귀 계수를 최적화하며, 규제<sup>Regularization</sup>를 적용하지 않은 모델이다.</li>\n",
    "    <li><b>릿지<sup>Ridge</sup>:</b> 릿지 회귀는 선형 회귀에 L2 규제를 추가한 회귀 모델이다. 릿지 회귀는 L2 규제를 적용하는데, L2 규제는 상대적으로 큰 회귀 계수 값의 예측 영향도를 감소시키기 위해서 회귀 계수값을 더 작게 만드는 규제 모델이다.</li>\n",
    "    <li><b>라쏘<sup>Lasso</sup>:</b> 라쏘 회귀는 선형 회귀에 L1 규제를 적용한 방식이다. L2 규제가 회귀 계수 값의 크기를 줄이는 데 반해, L1 규제는 예측 영향력이 작은 피처의 회귀 계수를 0으로 만들어 회귀 예측 시 피처가 선택되지 않게 하는 것이다. 이러한 특성 때문에 L1 규제는 피처 선택 기능으로도 불린다.</li>\n",
    "    <li><b>엘라스틱넷<sup>ElasticNet</sup>:</b>L2, L1 규제를 함께 결합한 모델이다. 주로 피처가 많은 데이터 세트에서 적용되며, L1 규제로 피처의 개수를 줄임과 동시에 L2 규제로 계수 값의 크기를 조정한다.</li>\n",
    "    <li><b>로지스틱 회귀<sup>Logistic Regression</sup>:</b> 로지스틱 회귀는 회귀라는 이름이 붙어 있지만, 사실은 분류에 사용되는 선형 모델이다. 로지스틱 회귀는 매우 강력한 분류 알고리즘이다. 일반적으로 이진 분류뿐만 아니라 희소 영역의 분류, 예를 들어 텍스트 분류와 같은 영역에서 뛰어난 예측 성능을 보인다.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a20e03",
   "metadata": {},
   "source": [
    "## 단순 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ccb6c",
   "metadata": {},
   "source": [
    "단순 선형 회귀는 독립변수도 하나, 종속변수도 하나인 선형 회귀다. 예를 들어, 주택 가격이 주택의 크기로만 결정된다고 하자. 일반적으로 주택의 크기가 크면 가격이 높아지는 경향이 있기 때문에 다음과 같이 주택 가격과 주택 크기에 대한 선형(직선 형태)의 관계로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd4b16",
   "metadata": {},
   "source": [
    "<b>그림 1</b> 단순 선형 회귀\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/reg.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d7715d",
   "metadata": {},
   "source": [
    "$\\mathrm{X}$축이 주택의 크기 축(평당 크기)이고 $\\mathrm{Y}$축이 주택의 가격 축인 2차원 평면에서 주택 가격은 특정 기울기와 절편을 가진 1차 함수식으로 모델링할 수 있다. 해당 문제의 선형 모델 공식은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d098da",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = w_0 + w_1\\mathrm{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efb67c",
   "metadata": {},
   "source": [
    "독립변수가 1개인 단순 선형 회귀에서는 이 기울기 $w1$과 절편 $w_0$을 회귀 계수로 지칭한다(절편은 intercept이다). 독립변수와 종속변수 사이의 관계를 나타내는 선형 방정식의 가중치를 학습하는 것이 목적이다. 이 방정식으로 훈련 데이터셋이 아닌 새로운 샘플의 타깃 값을 예측할 수 있다. 그리고 회귀 모델을 위와 같은 1차 함수로 모델링했다면 실제 주택 가격은 이러한 1차 함수 값에서 실제 값만큼의 오류 값을 뺀(또는 더한) 값이 된다($w_0 + w_1\\mathrm{X}$ + 오류 값)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865a87b",
   "metadata": {},
   "source": [
    "이렇게 실제 값과 회귀 모델의 차이에 따른 오류 값을 남은 오류, 즉 잔차라고 부른다. <mark>최적의 회귀 모델을 만든다는 것은 바로 전체 데이터의 잔차(오류 값, offset이라고도 한다) 합이 최소가 되는 모델을 만든다는 의미다. 동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미도 된다.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fa967",
   "metadata": {},
   "source": [
    "<b>그림 2</b> 잔차\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/reg2.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0329d14",
   "metadata": {},
   "source": [
    "오류 값은 +나 -가 될 수 있다. 그래서 전체 데이터의 오류 합을 구하기 위해 단순히 더했다가는 뜻하지 않게 오류 합이 크게 줄어들 수 있다. 따라서 보통 오류 합을 계산할 때는 절댓값을 취해서 더하는 MAE<sup>Mean Absolute Error</sup>, 오류 값의 제곱을 구해서 더하는 방식인 RSS<sup>Residual Sum of Square</sup>을 취한다. 일반적으로 미분 등의 계산을 편리하게 하기 위해서 RSS 방식으로 오류 합을 구한다. 즉, Error<sup>2</sup> = RSS이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6313a",
   "metadata": {},
   "source": [
    "<b>그림 3</b> RSS\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/reg3.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955be2d",
   "metadata": {},
   "source": [
    "RSS는 이제 변수가 $w_0, w_1$인 식으로 표현할 수 있으며, 이 RSS를 최소로 하는 $w_0, w_1$, 즉 회귀 계수를 학습을 통해서 찾는 것이 머신러닝 기반 회귀의 핵심 사항이다. RSS는 회귀식의 독립변수 X, 종속변수 Y가 중심 변수가 아니라 w 변수(회귀 계수)가 중심 변수임을 인지하는 것이 매우 중요하다(학습 데이터로 입력되는 독립변수와 종속변수는 RSS에서 모두 상수로 간주한다). 일반적으로 RSS는 학습 데이터의 건수로 나누어서 다음과 같이 정규화된 식으로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df37d03",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{RSS}(w_0, w_1) = \\frac{1}{N}\\sum_{i=1}^N(y_i - (w_0 + w_1x_1))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0c3cf",
   "metadata": {},
   "source": [
    "회귀에서 이 RSS는 비용<sup>cost</sup>이며 w 변수(회귀 계수)로 구성되는 RSS를 비용함수라고 한다. 머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 이 비용 함수가 반환하는 값(즉, 오류 값)을 지속해서 감소시키고 최종적으로 더 이상 감소하지 않는 최소의 오류 값을 구하는 것이다. 비용 함수를 손실 함수<sup>loss function</sup>라고도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323604a6",
   "metadata": {},
   "source": [
    "### 단순 선형 회귀 모델의 통계적 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07902d00",
   "metadata": {},
   "source": [
    "$\\varepsilon$(오차)는 확률 변수로 두는 경우가 많다. 이 전제를 세울 때 단순 선형 회귀 모델은 확률 시스템이 되고 모델의 좋고 나쁨은 통계적 평가를 거치게 된다. 특히, $\\varepsilon$이 정규분포를 따른다고 가정할 때의 평가지표는 이론적으로 입증되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f42eb",
   "metadata": {},
   "source": [
    "#### 회귀계수의 t검정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366eec4",
   "metadata": {},
   "source": [
    "단순 선형 회귀 모델이 확률시스템이라는 가정 아래, 회귀계수는 확률 변수가 되고 표본마다 그 값이 변한다. 특히 계수 $w_0, w_1$의 값이 0인가의 여부를 문제로 하고 싶은 경우가 있다. 이를 위해 다음의 가설검정을 실시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1211d3",
   "metadata": {},
   "source": [
    "$$\n",
    "H_0: \\text{계수는 0이다.}\\\\\n",
    "H_1: \\text{계수는 0이 아니다.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976d6f7",
   "metadata": {},
   "source": [
    "여기에서 계수는 $w_0$, 또는 $w_1$ 모두를 나타내고, 각각 별도로 검정을 실시한다. 각 계수에 관한 검정은 $\\varepsilon_i$의 분산을 이용하는 것이 되지만, 이 분산은 알지 못한다. 이 때문에 표본분산을 이용한 t 검정을 실시하게 된다. 각 계수에 대한 t검정통계량과 이것에 수반되는 값은 statsmodels이 계산하기 때문에 이 값을 보고 $H_0$를 기각할지의 여부를 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e12a4d",
   "metadata": {},
   "source": [
    "#### 결정계수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d6223",
   "metadata": {},
   "source": [
    "<b>결정계수</b><sup>coefficient of determination</sup>는 $R^2$로 표현하고, 회귀 모델의 데이터에 대해서 적합한 정도를 나타내는 지표로 statsmodels가 계산한다. 결정 계수는 다음의 범위를 취한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a61a5",
   "metadata": {},
   "source": [
    "$$\n",
    "0 < R^2 \\leq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fa893",
   "metadata": {},
   "source": [
    "이 식이 1에 가까울수록 잘 적합되었다고 판단하고 독립변수가 종속변수를 잘 설명하고 있다고 말한다. 일반적으로 자주 언급되지만 $R^2$가 0.6이하라면 좋지 않지만 0.8 이상이라면 어느 정도 좋은 모델이라고 판단된다. 하지만 이 값은 절대적 평가가 아니므로 0.6 이하라면 절대로 안 되고 0.8 이상이라면 절대로 좋은 것이라고 말할 수 없다. 결정계수 $R^2$의 값은 절대적인 지표가 아니라 어디까지나 기준이라는 것을 인식하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfeab0b",
   "metadata": {},
   "source": [
    "#### 가계 동향 조사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07545a",
   "metadata": {},
   "source": [
    "가계 동향 조사(통계청)의 Web 사이트에서 2인 이상 세대의 연간 수입에 대해, 1개월당 지출과 엥겔계수 각각에 대한 단순 회귀 분석을 실시한다. 가공한 데이터를 다음에 제시한 URL로 액세스하여 이 데이터를 읽어 들인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfd8b2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:48:07.291991Z",
     "start_time": "2023-01-23T07:48:04.332869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>engel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216</td>\n",
       "      <td>172462</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304</td>\n",
       "      <td>204599</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356</td>\n",
       "      <td>224776</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413</td>\n",
       "      <td>240153</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481</td>\n",
       "      <td>255497</td>\n",
       "      <td>27.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  expenditure  engel\n",
       "0     216       172462   30.8\n",
       "1     304       204599   29.9\n",
       "2     356       224776   28.8\n",
       "3     413       240153   27.8\n",
       "4     481       255497   27.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://sites.google.com/site/datasciencehiro/datasets/FamilyIncome.csv'\n",
    "df = pd.read_csv(url, comment='#')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833922b",
   "metadata": {},
   "source": [
    "데이터의 내용은 위와 같이 income(연간 수입 [10만 원]), expenditure(월간 지출), engel(엥겔계수)이 나열되었다. index의 값은 income의 순위 0(최저 수입) ~ 9(최고 수입)의 10등급을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0bb8ed",
   "metadata": {},
   "source": [
    "이 데이터에서 독립 변수를 income, 종속 변수를 expenditure로 하는 단순회귀분석은 다음과 같이 기술한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27602016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:53:09.030255Z",
     "start_time": "2023-01-23T07:53:08.998553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            expenditure   R-squared:                       0.987\n",
      "Model:                            OLS   Adj. R-squared:                  0.986\n",
      "Method:                 Least Squares   F-statistic:                     624.7\n",
      "Date:                Mon, 23 Jan 2023   Prob (F-statistic):           7.02e-09\n",
      "Time:                        16:53:09   Log-Likelihood:                -105.43\n",
      "No. Observations:                  10   AIC:                             214.9\n",
      "Df Residuals:                       8   BIC:                             215.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     1.4e+05   6550.516     21.366      0.000    1.25e+05    1.55e+05\n",
      "income       233.8560      9.356     24.994      0.000     212.280     255.432\n",
      "==============================================================================\n",
      "Omnibus:                        2.090   Durbin-Watson:                   1.074\n",
      "Prob(Omnibus):                  0.352   Jarque-Bera (JB):                1.285\n",
      "Skew:                          -0.825   Prob(JB):                        0.526\n",
      "Kurtosis:                       2.400   Cond. No.                     1.41e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.41e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\scipy\\stats\\stats.py:1541: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "result = smf.ols('expenditure ~ income', data=df).fit()\n",
    "w0, w1 = result.params\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6734226",
   "metadata": {},
   "source": [
    "여기에서 변수 w0, w1에는 단순 선형 회귀 모델의 절편항과 기울기가 반환된다. 또한, <code>smf.ols()</code>는 최소제곱법을 이용한 계산을 수행하고 인수 파라미터의 제공 방식은 R 언어 스타일의 표기법을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b06144",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>OLS(최소 제곱법)를 이용한 회귀분석 결과이고 목적변수(Dep. Variable)는 expenditure이다.</li>\n",
    "    <li>R-squared: 결정계수 $R^2$의 값은 0.987이다.</li>\n",
    "    <li>Intercept: 절편항, coef(계수값)는 1.4 x 10<sup>5</sup>, t는 계수에 관한 검정통계량의 값, P > |t|는 t 검정에서 p값이 0.000임을 나타내고 있다. 유의수준을 5%(0.05)로 할것까지도 없이 이 계수가 0이라는 가설은 기각된다. 즉, 이 값은 유의하게 존재한다고 할 수 있다.</li>\n",
    "    <li>income: 독립 변수 income의 계수에 대해서, 그 계수값, p값 등이 표시된다. 이것도 계수값이 0이 아님을 나타내고 있다. </li>\n",
    "    <li>std err(계수값의 산포도를 나타내는 표준편차), [0.025, 0.975] (유의수준 5%로 할 때의 계수의 구간추정, 계수의 하한값과 상한값)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957953bc",
   "metadata": {},
   "source": [
    "이 결과에 의해, 구해진 단순 선형 회귀 모델은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c9fe1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{expenditure} = w0 + w1 \\times \\text{income}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a5b6ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T08:01:58.620109Z",
     "start_time": "2023-01-23T08:01:58.442115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['income'], df['expenditure'], 'o')\n",
    "start, end = plt.xlim()\n",
    "plt.plot(np.arange(start, end, 0.1), w0 + w1 * np.arange(start, end, 0.1))\n",
    "plt.xlabel('income'); plt.ylabel('expenditure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063f4ce",
   "metadata": {},
   "source": [
    "이 그래프를 보고, 구해진 단순 선형 회귀 모델이 좋은 지표가 된다고 판단한다면, 데이터에는 없는 연간 수입이 1억 1,000만 원, 1억 2,000만 원인 가정의 월 지출액을 예측할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15626794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T08:03:59.855881Z",
     "start_time": "2023-01-23T08:03:59.841509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    397198.498402\n",
       "1    420584.101981\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewData = {'income': [1100, 1200]}\n",
    "Newdf = pd.DataFrame(NewData)\n",
    "pred = result.predict(Newdf)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016f64c",
   "metadata": {},
   "source": [
    "#### 심슨의 역설"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1d6a3",
   "metadata": {},
   "source": [
    "회귀분석을 바로 수행하지 않고, 그 전의 데이터 가시화도 포함하여 몇 가지 통계량을 살펴보고 나서 회귀분석을 실시한 뒤에 사전분석과 대조하여 확인한 후 결과를 평가하는 것이 바람직하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d702a0",
   "metadata": {},
   "source": [
    "이것을 게을리하여 잘못을 범하는 대표적인 예로 통계학에서 유명한 심슨의 역설<sup>Simpson's paradox</sup>이 있다. 이것은 모집단의 상관과 부분집단의 상관이 다른 경우가 있고 부분집단에서의 가설이나 통계분석 결과가 모집단과는 정반대의 결과가 나오는 것을 지적하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9e652",
   "metadata": {},
   "source": [
    "#### 수학적 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c5eac",
   "metadata": {},
   "source": [
    "엄밀한 수학에 의한 증명이나 도출을 수행하지 않고, 수식으로 표현된 항목이나 지표를 어떻게 생각하면 좋은가라는 <b>판단력을 기르는</b> 것에 초점을 맞추어 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61f381",
   "metadata": {},
   "source": [
    "우선 다음과 같이 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec7897",
   "metadata": {},
   "source": [
    "<b>취득 데이터:</b> $\\left\\{x_i, y_i\\right\\}\\,(i=1, ..., N)$<br>\n",
    "<b>실제 시스템:</b> $y_i = w_0 + w_1x_i + \\varepsilon_i,\\,\\varepsilon_i \\sim N(0, \\sigma^2)$<br>\n",
    "<b>회귀 모델:</b> $\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1x_i$<br>\n",
    "<b>$x, y$의 표본평균:</b> $\\hat{\\mu}_x, \\hat{\\mu}_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6299841",
   "metadata": {},
   "source": [
    "##### 회귀계수의 성질"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26b5a6",
   "metadata": {},
   "source": [
    "앞에 기술한 가정 하에 추정한 회귀계수의 성질은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057d7d4",
   "metadata": {},
   "source": [
    "<b>불편추정량:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84378e",
   "metadata": {},
   "source": [
    "$$\n",
    "E[\\hat{w}_0] = w_0,\\, E[\\hat{w}_1] = w_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b2d66",
   "metadata": {},
   "source": [
    "<b>일치추정량:</b> $N \\to \\infty$일 때 아래 계수의 분산은 0에 가까워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fc515",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2_{\\hat{w}_0} = \\mathrm{V}[\\hat{w}_0] = (\\frac{1}{N} + \\frac{\\hat{\\mu}_x^2}{\\sum_{i=1}^N(x_i - \\hat{\\mu}_x)})\\sigma^2\\,\\,\\,\\,\\text{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f126c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma_{\\hat{w}_1}^2 = \\mathrm{V}[\\hat{w}_1] = \\frac{\\sigma^2}{\\sum_{i=1}^N(x_i - \\hat{\\mu}_x)}\\,\\,\\,\\,\\text{(2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b8970",
   "metadata": {},
   "source": [
    "<b>정규성:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b5d744",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{w}_0 \\sim N(w_0, \\mathrm{V}[\\hat{w}_0]),\\,\\,\\,\\hat{w}_1 \\sim N(w_1, \\mathrm{V}[\\hat{w}_1])\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d41d814",
   "metadata": {},
   "source": [
    "이러한 성질 중에서 불편추정량과 일치추정량은 유용하게 이용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcc726",
   "metadata": {},
   "source": [
    "##### 회귀계수의 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155ebf9",
   "metadata": {},
   "source": [
    "추정한 회귀계수의 검정 개요를 기술한다. 우선 $\\hat{w}_1$을 대상으로 고려한다. 이것은 어느 특정값 $w_1$과 동일한가의 여부에 대한 검정을 고려한다. 이 경우의 가설은 $H_0: \\hat{w}_1 = w_1, H_1 = \\hat{w}_1 \\neq w_1$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb9580",
   "metadata": {},
   "source": [
    "모분산 $\\sigma^2$를 알지 못하므로 대신 다음의 $\\sigma^2$을 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371549b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\varepsilon_i = y_i - \\hat{y}_i = y_i - (\\hat{w}_0 + \\hat{w}_1x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57dc4f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{N - 2}\\sum_{i=1}^N\\varepsilon_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209349bc",
   "metadata": {},
   "source": [
    "두 번째 식에서 N - 2로 나눈 이유는 회귀계수를 최소제곱법으로 구할 때 $\\varepsilon_i$의 총합은 0, 또한 변수 벡터와 계수 벡터의 내적을 0으로 한다는 두 가지 제약이 가해져서 자유도가 2만큼 줄어들기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e398879",
   "metadata": {},
   "source": [
    "식 (2)의 $\\sigma^2$대신 $\\hat{\\sigma}^2$을 이용하여 $\\mathrm{V}[\\hat{w}_1](\\hat{\\sigma}^2)$으로 나타낸다. 이것을 이용하여 $\\hat{w}_1$의 검정통계량을 다음 식으로 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c4e4a",
   "metadata": {},
   "source": [
    "$$\n",
    "t_{w_1} = \\frac{\\hat{w}_1 - w_1}{\\sqrt{\\mathrm{V}[\\hat{w}_1](\\hat{\\sigma}^2)}}\\sim t(N - 2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c12b0",
   "metadata": {},
   "source": [
    "이 $t_{w_1}$은 통계의 검정에서 나타나는 것과 동일한 형식이기 때문에 검정과 동일한 검정절차 $w_0$를 수행하게 된다. 다만 자유도 N - 2인 t분포를 따르는 것에 주의하기 바란다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76777760",
   "metadata": {},
   "source": [
    "$w_0$에 관해서도 동일한 검정을 수행할 수 있는 검정통계량이 도출된다. statsmodels의 회귀분석에서는 $w_0 = w_1 = 0$으로 두고 $w_0$ 및 $w_1$이 개별적으로 0이 되는가에 여부에 대한 검정을 수행하고 그 결과를 P > |t|로 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfaf594",
   "metadata": {},
   "source": [
    "##### 결정계수 R<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9f5b4",
   "metadata": {},
   "source": [
    "결정계수는 다음 식으로 정의된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d334b",
   "metadata": {},
   "source": [
    "$$\n",
    "R^2 = \\frac{\\sum_{i=1}^N(\\hat{y}_i - \\hat{\\mu}_y)^2}{\\sum_{i=1}^N(y_i - \\hat{\\mu}_y)^2} = 1 - \\frac{\\sum_{i=1}^N(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N(y_i - \\hat{\\mu}_y)^2}\\,\\,\\,(0\\leq R^2 \\leq 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588ac12",
   "metadata": {},
   "source": [
    "가운데 식을 보면 분자가 모델 출력 $\\hat{y}$의 분산, 분모가 시스템 출력 $y$의 분산이라고 볼 수 있고 분산비를 나타내고 있다. 이것을 통계에서는 변동비라고 부른다. 따라서 최적적합의 $R^2 = 1$이라는 것은 분산이 동일하다는 것을 기술하고 있다. 통계량인 분산이나 평균이 동일하더라도, 다른 데이터 계열을 나타내는 경우는 자주 있다. 따라서 이것만을 살펴보면 $R^2$가 잘 적합되었다는 것을 나타내는 지표가 될 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68713d7d",
   "metadata": {},
   "source": [
    "그러나 오른쪽 식의 두 번째 항 분자를 보면 시스템과 모델 출력의 오차분산을 측정하고 이것은 일치성을 측정하는 지표이므로 이 관점으로부터 $R^2$가 잘 적합되었다는 것을 나타내는 지표가 된다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57e633",
   "metadata": {},
   "source": [
    "가운데 식이 도움이 안 되는가하면 그렇지도 않다. 세상에는 적합보다는 분산비(즉, 에너지비)를 중요시하는 분야도 있고 이러한 관점에서 보면 유용한 표현이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41b334",
   "metadata": {},
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c727ab",
   "metadata": {},
   "source": [
    "앞서 독립 변수가 하나인 단순 선형 회귀로 선형 회귀의 개념을 잠깐 살펴보았다. 이제는 독립 변수를 여러 개로 확장시켜서 일반화해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3c684",
   "metadata": {},
   "source": [
    "더 일반적으로 선형 모델은 입력 특성의 가중치 합과 <b>편향</b><sup>bias</sup>(또는 <b>절편</b><sup>intercept</sup>)이라는 상수를 더해 예측을 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272cb5d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\cdots + \\theta_mx_m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32afd4",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>$\\hat{y}$는 예측값이다.</li>\n",
    "    <li>$m$은 특성의 수다.</li>\n",
    "    <li>$x_i$는 $i$번째 특성값이다.</li>\n",
    "    <li>$\\theta_j$는 $j$번째 모델 파라미터다(편향 $\\theta_0$과 특성의 가중치 $\\theta_1, \\theta_2, \\cdots, \\theta_m$을 포함한다).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3603c20",
   "metadata": {},
   "source": [
    "이 식은 다음 식처럼 벡터 형태로 더 간단하게 쓸 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18494ccc",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = h_{\\theta}(\\mathrm{x}) = \\mathrm{\\theta\\cdot x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f823d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>$\\mathrm{\\theta}$는 편향 $\\theta_0$과 $\\theta_1$에서 $\\theta_m$까지의 특성 가중치를 담은 모델의 파라미터 벡터다.</li>\n",
    "    <li>$\\mathrm{x}$는 $x_0$에서 $x_m$까지 담은 샘플의 <b>특성 벡터</b>다. $x_0$는 항상 1이다.<sup><a id=\"a01\" href=\"#p01\">[1]</a></sup></li>\n",
    "    <li>$\\mathrm{\\theta\\cdot x}$는 벡터 $\\theta$와 $\\mathrm{x}$의 점곱이다. 이는 $\\theta_0x_0+\\theta_1x_1+\\cdots+\\theta_mx_m$와 같다.</li>\n",
    "    <li>$h_{\\theta}$는 모델 파라미터 $\\theta$를 사용한 가설<sup>hypothesis</sup>함수다.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6267d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D3D3D3; padding:10px;\">\n",
    "    <span style=\"color: green\"><strong>NOTE_</strong></span>머신러닝에서는 종종 벡터를 하나의 열을 가진 2D 배열인 <b>열 벡터</b><sup>column vector</sup>로 나타낸다. $\\theta$와 $\\mathrm{x}$가 열 벡터라면 예측은 $\\hat{y} = \\theta^T\\mathrm{x}$이다. 여기에서 $\\theta^T$는 $\\theta$의 전치<sup>Transpose</sup>이다(열 벡터가 아니라 행 벡터가 된다). $\\theta^T\\mathrm{x}$는 $\\theta^T$와 $\\mathrm{x}$의 행렬 곱셈이다. 물론 예측 결과는 같지만 스칼라 값이 아니라 하나의 원소를 가진 행렬이 만들어진다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93576c5e",
   "metadata": {},
   "source": [
    "이것이 선형 회귀 모델이다. 이제 선형 회귀 모델을 훈련시켜보자. 모델을 훈련시킨다는 것은 모델이 훈련 세트에 가장 잘 맞도록 모델 파라미터를 설정하는 것이다. 이를 위해 먼저 모델이 훈련 데이터에 얼마나 잘 들어맞는지 측정해야 한다. 회귀에 가장 널리 사용되는 성능 측정 지표는 평균 제곱근 오차<sup>RMSEM</sup>이다. 그러므로 선형 회귀 모델을 훈련시키려면 RMSE를 최소화하는 $\\theta$를 찾아야 한다. 실제로는 RMSE보다 평균 제곱 오차<sup>mean square error</sup>(MSE)를 최소화하는 것이 같은 결과를 내면서(어떤 함수를 최소화하는 것은 그 함수의 제곱근을 최소화하는 것과 같으므로) 더 간단하다.<sup><a id=\"a02\" href=\"#p02\">[2]</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6f553",
   "metadata": {},
   "source": [
    "훈련 세트 $\\mathrm{X}$에 대한 선형 회귀 가설 $h_{\\theta}$의 MSE는 다음 식처럼 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa8b126",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MSE}(\\mathrm{X}, h_{\\theta}) = \\frac{1}{n}\\sum_{i=1}^n(y^{(i)} - \\theta^T\\mathrm{x}^{(i)})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9023bf2",
   "metadata": {},
   "source": [
    "## 회귀 모델의 확률적 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf125b",
   "metadata": {},
   "source": [
    "앞서 말했듯, 회귀 문제는 여러 독립 변수와 종속 변수의 관계를 연속 함수 형태로 분석하는 문제이다. 관측 항목을 독립 변수화 종속 변수로 나누고 이들의 관계를 함수 형태로 분석한다. 데이터를 관측할 때 발생하는 관측 오차 또는 실험 오차는 <b>가우시안 분포</b><sup>Gaussian distribution</sup>로 정의되므로, 회귀 문제는 가우시안 분포를 예측하는 모델로 정의할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8776118b",
   "metadata": {},
   "source": [
    "관측 데이터를 수집할 때마다 값이 조금씩 달라지는데 이런 변동분을 관측 오차<sup>observational error</sup>라고 한다. 관측 오차를 노이즈<sup>noise</sup>라고도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cc199",
   "metadata": {},
   "source": [
    "### 가우시안 분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f5b35",
   "metadata": {},
   "source": [
    "가우시안 분포는 평균을 중심으로 대칭적인 종 모양의 사건이 발생할 확률을 나타내며 다음과 같은 식으로 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a4b91",
   "metadata": {},
   "source": [
    "$$\n",
    "N(x|\\mu,\\,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f24df",
   "metadata": {},
   "source": [
    "$x$는 확률 변수, $\\mu$는 평균, $\\sigma^2$는 분산, $\\sigma$는 표준편차다. 가우시안 분포는 관측 데이터의 분포를 근사하는 데에 자주 쓰인다. 중심 극한 정리<sup>central limit therem</sup>에 따라 독립적인 확률 변수들의 평균은 가우시안 분포에 가까워지는 성질이 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838b807",
   "metadata": {},
   "source": [
    "<b>그림 4</b> 가우시안 분포\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/GD.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d119270f",
   "metadata": {},
   "source": [
    "### 회귀 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605173af",
   "metadata": {},
   "source": [
    "회귀 문제를 확률 모델로 정의해 보자. 관측 데이터는 $D = \\left\\{(x_i, t_i): i=1, ..., N\\right\\}$로 N개의 $(x_i, t_i)$ 샘플로 구성된다. 입력 데이터 $x_i$는 같은 분포에서 독립적으로 샘플링되어 i.i.d를 만족한다고 하자. 타깃 $t_i$는 모델 예측값 $y(x_i; \\theta)$에 관측 오차 $\\varepsilon$가 더해진 값으로 정의되며 관측 오차 $\\varepsilon$는 가우시안 분포 $N(\\varepsilon|0,\\,\\beta^{-1})$를 따른다고 가정한다. 이때 오차의 분산 $\\beta^{-1}$는 정밀도<sup>precision</sup> $\\beta$의 역수로 상수로 가정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83120ecc",
   "metadata": {},
   "source": [
    "분산과 정밀도는 서로 역수 관계다. 즉, 분산이 크면 정밀하지 않은 것으로 생각하고, 분산이 작으면 정밀한 것으로 생각할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1bd5d",
   "metadata": {},
   "source": [
    "여기서는 설명을 간단히 하기 위해서 회귀 문제의 타깃이 실수라고 가정하고 설명하고 있지만 일반적으로 타깃은 다차원 공간의 연속 함수에 있는 한 점이다. 이는 실수 벡터로 표현하며 타깃의 분포는 다변량 가우시안 분포가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0591099",
   "metadata": {},
   "source": [
    "$$\n",
    "t_i = y(x_i;\\,\\theta) + \\varepsilon,\\,\\varepsilon \\sim N(\\varepsilon|0, \\beta^{-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ada543",
   "metadata": {},
   "source": [
    "다음 그림에서 회색 점은 관측 데이터의 타깃 $t_i$이다. 입력 $x_i$마다 관측 데이터인 타깃 $t_i$의 가우시안 분포가 달라진다. 예를 들어 $x_i$를 집값을 예측하기 위한 입력인 '방이 3개, 32평, 아파트, 역과의 거리가 20분 거리'라고 하면 회색 점들은 집값 관측 데이터인 $t_i$이다. 따라서 동일한 입력 $x_i$마다 여러 회색 점들이 존재하므로 집값의 분포를 이루게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199776a",
   "metadata": {},
   "source": [
    "<b>그림 5</b> 회귀 문제에서 확률 모델의 가우시안 분포 예측\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/회귀모델의 가우시안분포.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12e0d1",
   "metadata": {},
   "source": [
    "따라서 회귀 모델은 입력 $x_i$가 주어졌을 때 타깃 $t_i$의 조건부 확률분포인 $p(t_i|x_i;\\,\\theta)$를 예측한다. 관측 오차 $\\varepsilon$은 가우시안 분포 $N(\\varepsilon|0,\\,\\beta^{-1})$로 가정했기 때문에 타깃 $t_i$의 분포는 관측 오차의 분산 $\\beta^{-1}$를 갖는 가우시안 분포 $N(t_i|y(x_i;\\,\\theta), \\beta^{-1})$로 정의된다. 따라서 신경망 모델은 평균 $y(x_i;\\,\\theta)$만 예측하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1501822",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa5fc1e9",
   "metadata": {},
   "source": [
    "## 정규방정식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6c4b6",
   "metadata": {},
   "source": [
    "비용 함수를 최소화하는 $\\theta$값을 찾기 위한 <b>해석적인 방법</b>이 있다. 다른 말로 하면 바로 결과를 얻을 수 있는 수학 공식이 있다. 이를 <b>정규방정식</b><sup>normal equation</sup>이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71392e7b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\theta} = (\\mathrm{X^TX})^{-1}\\mathrm{X^Ty}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881bf7f",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>$\\hat{\\theta}$는 비용 함수를 최소화하는 $\\theta$값이다.</li>\n",
    "    <li>$\\mathrm{y}$는 $y_1$부터 $y_n$까지 포함하는 타깃 벡터다.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee00b2",
   "metadata": {},
   "source": [
    "이 공식을 테스트하기 위해 선형처럼 보이는 데이터를 생성하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c36398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:16.956624Z",
     "start_time": "2023-01-23T04:03:16.028683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: generated_data_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "save_fig(\"generated_data_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63fb11b",
   "metadata": {},
   "source": [
    "그럼 이제 정규방정식을 사용해 $\\hat{\\theta}$을 계산해보겠다. 넘파이 선형대수 모듈(np.linalg)에 있는 <code>inv()</code> 함수를 사용해 역행렬을 계산하고 <code>dot()</code> 메서드를 사용해 행렬 곱셈을 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f32d3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.003071Z",
     "start_time": "2023-01-23T04:03:16.958629Z"
    }
   },
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X] # 모든 샘플에 x0 = 1을 추가\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e554321",
   "metadata": {},
   "source": [
    "이 데이터를 생성하기 위해 사용하는 함수는 $y = 4 + 3x_1 + \\text{가우시안_잡음}$이다. 정규방정식으로 계산한 값을 확인해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e537aaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.018599Z",
     "start_time": "2023-01-23T04:03:17.005077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [2.77011339]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949217d4",
   "metadata": {},
   "source": [
    "$\\theta_0=4.215$와 $\\theta_1=2.770$ 대신 $\\theta_0=4$와 $\\theta_1=3$을 기대했었다. 매우 비슷하지만 잡음 때문에 원래 함수의 파라미터를 정확하게 재현하지 못했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd204870",
   "metadata": {},
   "source": [
    "$\\hat{\\theta}$을 사용해 예측을 해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28e36d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.034171Z",
     "start_time": "2023-01-23T04:03:17.020599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [9.75532293]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8f0e0",
   "metadata": {},
   "source": [
    "모델의 예측을 그래프에 나타내보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be18939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.624817Z",
     "start_time": "2023-01-23T04:03:17.037171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: linear_model_predictions_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "save_fig(\"linear_model_predictions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80451cb",
   "metadata": {},
   "source": [
    "사이킷런에서 선형 회귀를 수행하는 것은 간단하다.<sup><a id=\"a03\" href=\"p03\">[3]</a></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47313c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.949375Z",
     "start_time": "2023-01-23T04:03:17.627852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.21509616]), array([[2.77011339]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2e594d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.964745Z",
     "start_time": "2023-01-23T04:03:17.951880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [9.75532293]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34271dae",
   "metadata": {},
   "source": [
    "LinearRegression 클래스는 <code>scipy.linalg.lstsq()</code> 함수('최소 제곱<sup>least squares</sup>'에서 이름을 따왔다)를 기반으로 한다. 이 함수를 직접 호출할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1606693d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:03:17.980800Z",
     "start_time": "2023-01-23T04:03:17.966906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [2.77011339]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6)\n",
    "theta_best_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a62ec6",
   "metadata": {},
   "source": [
    "이 함수는 $\\hat{\\theta} = \\mathrm{X^+y}$을 계산한다. 여기에서 $\\mathrm{X^+}$는 $\\mathrm{X}$의 <b>유사역행렬</b><sup>pseudoinverse</sup>이다(정확하게는 무어-펜로즈<sup>Moore-Penrose</sup> 역행렬이다). <code>np.linalg.pinv()</code> 함수를 사용해 유사역행렬을 직접 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb21991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T04:17:55.441460Z",
     "start_time": "2023-01-23T04:17:55.428434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [2.77011339]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.pinv(X_b).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69830f8",
   "metadata": {},
   "source": [
    "유사역행렬 자체는 <b>특잇값 분해</b><sup>singular value decomposition</sup>(SVD)라 부르는 표준 행렬 분해 기법을 사용해 계산된다. SVD는 훈련 세트 행렬 $\\mathrm{X}$를 3개의 행렬 곱셈 $\\mathrm{U\\Sigma V^T}$로 분해한다(<code>numpy.linalg.svd()</code>를 참고). 유사역행렬은 $\\mathrm{X^+} = \\mathrm{V\\Sigma U^T}$로 계산된다. $\\Sigma^+$를 계산하기 위해 알고리즘이 $\\Sigma$를 먼저 구하고 그다음 어떤 낮은 임곗값보다 작은 모든 수를 0으로 바꾼다. 그다음 0이 아닌 모든 값을 역수로 치환한다. 마지막으로 만들어진 행렬을 전치한다. 정규방정식을 계산하는 것보다 이 방식이 훨씬 효율적이다. 또한 극단적인 경우도 처리할 수 있다. 실제로 $n < m$이거나 어떤 특성이 중복되어 행렬 $\\mathrm{X^TX}$의 역행렬이 없다면(즉, 특이 행렬이라면) 정규방정식이 작동하지 않는다. 하지만 유사역행렬은 항상 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfaea4",
   "metadata": {},
   "source": [
    "## 계산 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd224c",
   "metadata": {},
   "source": [
    "정규방정식은 $(m + 1)\\times(m + 1)$ 크기가 되는 $\\mathrm{X^TX}$의 역행렬을 계산한다($m$은 특성 수). 역행렬을 계산하는 <b>계산 복잡도</b><sup>computational complexity</sup>는 일반적으로 $O(m^{2.4})$에서 $O(m^3)$ 사이다(구현 방법에 따라 차이가 있다). 다시 말해 특성 수가 두 배로 늘어나면 계산 시간이 대략 $2^{2.4} = 5.3$에서 $2^3 = 8$배로 증가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae534579",
   "metadata": {},
   "source": [
    "사이킷런의 LinearRegression 클래스가 사용하는 SVD 방법은 약 $O(m^2)$이다. 특성의 개수가 두 배로 늘어나면 계산 시간이 대략 4배가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c065dd",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D3D3D3; padding:10px;\">\n",
    "    <span style=\"color: red\"><strong>CAUTION_</strong></span>정규방정식과 SVD 방법 모두 특성 수가 많아지면 (예를 들어 100,000) 매우 느려진다. 다행인 것은 훈련 세트의 샘플 수에 대해서는 선형적으로 증가한다(둘 다 $O(n)$이다).<sup><a id=\"a04\" href=\"#p04\">[4]</a></sup> 따라서 메모리 공간이 허락된다면 큰 훈련 세트도 효율적으로 처리할 수 있다.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2206d",
   "metadata": {},
   "source": [
    "또한 (정규방정식이나 다른 알고리즘으로) 학습된 선형 회귀 모델은 예측이 매우 빠르다. 예측 계산 복잡도는 샘플 수와 특성 수에 선형적이다. 다시 말해 예측하려는 샘플이 두 배로 늘어나면(또는 특성이 두 배로 늘어나면) 걸리는 시간도 거의 두 배 증가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77877cdf",
   "metadata": {},
   "source": [
    "이제 아주 다른 방법으로 선형 회귀 모델을 훈련시켜보겠다. 이 방법은 특성이 매우 많고 훈련 샘플이 너무 많아 메모리에 모두 담을 수 없을 때 적합하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac32507",
   "metadata": {},
   "source": [
    "# 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bd2de",
   "metadata": {},
   "source": [
    "<b>경사 하강법</b><sup>gradient descent</sup>(GD)은 여러 종류의 문제에서 최적의 해법을 찾을 수 있는 일반적인 최적화 알고리즘이다.  경사 하강법의 사전적 의미인 '점진적인 하강'이라는 뜻에서도 알 수 있듯이, '점진적으로' 반복적인 계산을 통해 $\\theta$ 파라미터 값을 업데이트하면서 오류 값이 최소(즉 비용 함수를 최소화하는)가 되는 $\\theta$ 파라미터를 구하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff245a",
   "metadata": {},
   "source": [
    "경사 하강법은 반복적으로 비용 함수의 반환 값, 즉 예측값과 실제 값의 차이가 작아지는 방향성을 가지고 $\\theta$ 파라미터를 지속해서 보정해 나간다. 최초 오류 값이 100이었다면 두 번째 오류 값은 100보다 작은 90, 세 번째는 80과 같은 방식으로 지속해서 오류를 감소시키는 방향으로 $\\theta$ 값을 계속 업데이터해 나간다. 그리고 오류 값이 더 이상 작아지지 않으면 그 오류 값을 최소 비용으로 판단하고 그때의 $\\theta$ 값을 최적 파라미터로 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb335d",
   "metadata": {},
   "source": [
    "강조하지만, 경사 하강법의 핵심은 \"어떻게 하면 오류가 작아지는 방향으로 $\\theta$ 값을 보정할 수 있을까?\"이다. 비용 함수가 다음 그림과 같은 포물선 형태의 2차 함수라면 경사 하강법은 최초 임의의 값(<b>무작위 초기화</b><sup>random initialization</sup>라고 한다) $\\theta$에서부터 미분을 적용한 뒤 이 미분 값이 계속 감소하는 방향으로 순차적으로 $\\theta$를 업데이터한다. 마침내 더 이상 미분된 1차 함수의 기울기가 감소하지 않는 지점을 비용 함수가 최소인 지점으로 간주하고 그때의 $\\theta$를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f391669",
   "metadata": {},
   "source": [
    "<b>그림 6</b> 이 경사 하강법 그림에서 모델 파라미터가 무작위하게 초기화된 후 반복적으로 수정되어 비용 함수를 최소화한다. 학습 스텝 크기는 비용 함수의 기울기에 비례한다.  따라서 파라미터가 최솟값에 가까워질수록 스텝 크기가 점진적으로 줄어든다.\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/gd_image.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff28afc",
   "metadata": {},
   "source": [
    "경사 하강법에서 중요한 파라미터는 스텝의 크기로, <b>학습률</b><sup>learning rate</sup> 하이퍼파라미터로 결정된다. 학습률이 너무 작으면 알고리즘이 수렴하기 위해 반복을 많이 진행해야 하므로 시간이 오래 걸린다(그림 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1683b",
   "metadata": {},
   "source": [
    "<b>그림 7</b> 학습률이 너무 작을 때\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/low_lr.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97f688",
   "metadata": {},
   "source": [
    "학습률이 너무 크면 골짜기를 가로질러 반대편으로 건너뛰게 되어 이전보다 더 높은 곳으로 올라가게 될지도 모른다. 이는 알고리즘을 더 큰 값으로 발산하게 만들어 적절한 해법을 찾지 못하게 한다(그림 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf22d2f",
   "metadata": {},
   "source": [
    "<b>그림 8</b> 학습률이 너무 클 때\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/high_lr.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676cc8c6",
   "metadata": {},
   "source": [
    "모든 비용 함수가 매끈한 그릇과 같지는 않다. 패인 곳, 산마루, 평지 등 특이한 지형이 있으면 최솟값으로 수렴하기 매우 어렵다. [그림 9]는 경사 하강법의 두 가지 문제점을 보여준다. 무작위 초기화 때문에 알고리즘이 왼쪽에서 시작하면 <b>전역 최솟값</b><sup>global minimum</sup>보다 덜 좋은 <b>지역 최솟값</b><sup>local minimum</sup>에 수렴한다. 알고리즘이 오른쪽에서 시작하면 평탄한 지역을 지나기 위해 시간이 오래 걸리고 일찍 멈추게 되어 전역 최솟값에 도달하지 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54e3a1",
   "metadata": {},
   "source": [
    "<b>그림 9</b> 경사 하강법의 문제점\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/gd_pro.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617015ef",
   "metadata": {},
   "source": [
    "다행시 선형 회귀를 위한 MSE 비용 함수는 곡선에서 어떤 두 점을 선택해 선을 그어도 곡선을 가로지르지 않는 <b>볼록 함수</b><sup>convex function</sup>이다.<sup><a id=\"a05\" href=\"#p05\">[5]</a></sup> 이는 지역 최솟값이 없고 하나의 전역 최솟값만 있다는 뜻이다. 또한 연속된 함수이고 기울기가 갑자기 변하지 않는다.<sup><a id=\"a06\" href=\"#p06\">[6]</a></sup> 이 두 사실로부터 경사 하강법이 전역 최솟값에 가깝게 접근할 수 있다는 것을 보장한다(학습률이 너무 높지 않고 충분한 시간이 주어지면)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9f1cc",
   "metadata": {},
   "source": [
    "사실 비용 함수는 그릇 모양을 하고 있지만 특성들의 스케일이 매우 다르면 길쭉한 모양일 수 있다. [그림 10]은 특성 1과 특성 2의 스케일이 같은 훈련 세트(왼쪽)과 특성 1이 특성 2보다 더 작은 훈련 세트(오른쪽)에 대한 경사 하강법을 보여준다.<sup><a id=\"a07\" href=\"#p07\">[7]</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11f25f",
   "metadata": {},
   "source": [
    "<b>그림 10</b> 특성 스케일을 적용한 경사 하강법(왼쪽)과 적용하지 않은 경사 하강법(오른쪽)\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/Regression/특성 스케일.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b04f9e",
   "metadata": {},
   "source": [
    "그림에서 볼 수 있듯이 왼쪽의 경사 하강법 알고리즘이 최솟값으로 곧장 진행하고 있어 빠르게 도달한다. 반면에 오른쪽 그래프는 처음에 전역 최솟값의 방향에 거의 직각으로 향하다가 평편한 골짜기를 길게 돌아서 나간다. 결국 최솟값에 도달하겠지만 시간이 오래 걸릴 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7eeb4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D3D3D3; padding:10px;\">\n",
    "    <span style=\"color: red\"><strong>CAUTION_</strong></span>경사 하강법을 사용할 때는 반드시 모든 특성이 같은 스케일을 갖도록 만들어야 한다(예를 들면 사이킷런의 StandardScaler를 사용하여). 그렇지 않으면 수렴하는 데 훨씬 오래 걸린다.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dffe6",
   "metadata": {},
   "source": [
    "앞의 그림은 모델 훈련이 (훈련 세트에서) 비용 함수를 최소화하는 모델 파라미터의 조합을 찾는 일임을 설명해준다. 이를 모델의 <b>파라미터 공간</b><sup>parameter space</sup>에서 찾는다고 말한다. 모델이 가진 파라미터가 많을수록 이 공간의 차원은 커지고 검색이 더 어려워진다. 300차원의 건초더미에서 바늘을 찾는 것은 차원이 3개뿐일 때보다 훨씬 어렵다. 다행히 선형 회귀의 경우 비용 함수가 볼록 함수이기 때문에 이 바늘은 그릇의 맨 아래에 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ee35d",
   "metadata": {},
   "source": [
    "## 배치 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23acb9",
   "metadata": {},
   "source": [
    "경사 하강법을 구현하려면 각 모델 파라미터 $\\theta_j$에 대해 비용 함수의 그레디언트를 계산해야 한다. 다시 말해 $\\theta_j$가 조금 변경될 때 비용 함수가 얼마나 바뀌는지 계간해야 한다. 이를 <b>편도 함수</b><sup>partial derivative</sup>라고 한다. 이는 '동쪽을 바라봤을 때 발밑에 느껴지는 산의 기울기는 얼마인가?'와 같은 질문이다. 그리고 같은 질문을 북쪽에 대해서도 한다(3차원 이상의 세상이라 가정하면 다른 모든 차원에 대해서도 반복한다). 다음 식은 파라미터 $\\theta_j$에 대한 비용 함수의 편도함수 $\\frac{\\partial}{\\partial \\theta_j}\\text{MSE}(\\theta)$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a303c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_j}\\text{MSE}(\\theta) = \\frac{2}{n}(\\mathrm{y^{(i)}} - \\theta^T\\mathrm{x}^{(i)})x_j^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffed7e",
   "metadata": {},
   "source": [
    "앞에서 언급한 비용 함수 $\\text{MSE}(\\theta_0, \\theta_1)$를 편의상 $C(\\theta)$로 지칭하겠다. $C(\\theta)$는 변수가 $\\theta$로 이뤄진 함수이며, $C(\\theta) = \\frac{1}{n}\\sum_{i=1}^n(y^{(i)} - (\\theta_0 + \\theta_1x_i))^2$이다. $C(\\theta)$를 미분해서 미분 함수의 최솟값을 구해야 하는데, $C(\\theta)$는 두 개의 $\\theta$ 파라미터인 $\\theta_0$와 $\\theta_1$을 각각 가지고 있기 때문에 일반적인 미분을 적용할 수가 없고, $\\theta_0, \\theta_1$ 각 변수에 편미분을 적용해야 한다. $C(\\theta)$를 최소화하는 $\\theta_0$와 $\\theta_1$의 값은 $C(\\theta)$를 $\\theta_1, \\theta_0$으로 편미분을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a1a0f",
   "metadata": {},
   "source": [
    "우선 비용함수 $C(\\theta)$를 정리하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222377f3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "C(\\theta_0, \\theta_1) &= \\frac{1}{n}\\sum_{i=1}^n(y^{(i)} - (\\theta_0 + \\theta_1x^{(i)}))^2\\\\\n",
    " &= \\frac{1}{n}\\sum_{i=1}^n(y^{(i)2} - 2y^{(i)}(\\theta_0 + \\theta_1x^{(i)}) + (\\theta_0 + \\theta_1x^{(i)})^2)\\\\\n",
    " &= \\frac{1}{n}\\sum_{i=1}^n(y^{(i)2} - 2y^{(i)}(\\theta_0 + \\theta_1x^{(i)}) + \\theta_0^2 + 2\\theta_0\\theta_1x^{(i)} + \\theta_1^2x^{(i)2})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242c5b4",
   "metadata": {},
   "source": [
    "① $\\theta_1$으로 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2e029",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\,C(\\theta_0, \\theta_1)}{\\partial\\,\\theta_1} &= \\frac{1}{n}\\sum_{i=1}^n(-2y^{(i)}x^{(i)} + 2\\theta_0x^{(i)} + 2\\theta_1x^{(i)2})\\\\\n",
    " &= \\frac{2}{n}\\sum_{i=1}^n-x^{(i)}(y^{(i)} - \\theta_0-\\theta_1x^{(i)})\\\\\n",
    " &= \\frac{2}{n}\\sum_{i=1}^n-x^{(i)}(y^{(i)} - (\\theta_0 + \\theta_1x^{(i)}))\\\\\n",
    " &= -\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea396cf",
   "metadata": {},
   "source": [
    "② $\\theta_0$으로 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853dab97",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\,C(\\theta_0, \\theta_1)}{\\partial\\,\\theta_0}&= \\frac{1}{n}\\sum_{i=1}^n(-2y^{(i)} + 2\\theta_0 + 2\\theta_1x^{(i)})\\\\\n",
    " &= -\\frac{2}{n}\\sum_{i=1}^n(y^{(i)} - (\\theta_0 + \\theta_1x^{(i)})\\\\\n",
    " &= -\\frac{2}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26242b7",
   "metadata": {},
   "source": [
    "$\\theta_1, \\theta_0$의 편미분 결괏값인, $-\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$, $-\\frac{2}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$을 반복적으로 보정하면서 $\\theta_1, \\theta_0$ 값을 업데이트하면 비용 함수 $C(\\theta)$가 최소가 되는 $\\theta_1, \\theta_0$의 값을 구할 수 있다. 업데이트는 새로운 $\\theta_1$에서 편미분 결괏값을 마이너스(-)하면서 적용한다. 즉 새로운 $\\theta_1 = $ 이전 $\\theta_1 - (-\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)}))$이다. 위 편미분 값이 너무 클 수 있기 때문에 앞서 말한 학습률 보정 계수 $\\eta$를 곱한다. 요약하자면, 경사 하강법은 $\\text{새로운} \\theta_1 = \\text{이전} \\theta_1 + \\eta\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)}),\\\\ \\text{새로운}\\theta_0 = \\text{이전}\\theta_0 + \\eta\\frac{2}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$을 반복적으로 적용하면서 비용 함수가 최소가 되는 값을 찾는다. 경사 하강법의 일반적인 프로세스는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e6eab",
   "metadata": {},
   "source": [
    "<b>Step 1:</b> $\\theta_1, \\theta_0$를 임의의 값으로 설정하고 첫 비용 함수의 값을 계산한다.<br>\n",
    "<b>Step 2:</b> $\\theta_1$을 $\\theta_1 + \\eta\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$, $\\theta_0$을 $\\theta_0 + \\eta\\frac{2}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$으로 업데이트한 후 다시 비용 함수의 값을 계산한다.<br>\n",
    "<b>Step 3:</b> 비용 함수의 값이 감소했으면 다시 Step 2를 반복한다. 더 이상 비용 함수의 값이 감소하지 않으면 그때의 $\\theta_1, \\theta_0$를 구하고 반복을 중지한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485311f",
   "metadata": {},
   "source": [
    "편도함수를 각각 계산하는 대신 다음 식을 사용하여 한꺼번에 계산할 수 있다. 그레디언트 벡터 $\\triangledown_\\theta\\text{MSE}(\\theta)$는 비용 함수의 (모델 파라미터마다 한 개씩인) 편도함수를 모두 담고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d02fa7",
   "metadata": {},
   "source": [
    "$\\triangledown_\\theta\\text{MSE}(\\theta) = \\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial\\theta_0}\\text{MSE}(\\theta) \\\\\n",
    "\\frac{\\partial}{\\partial\\theta_1}\\text{MSE}(\\theta) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial\\theta_m}\\text{MSE}(\\theta) \\end{pmatrix} = \\frac{2}{n}\\mathrm{X}^T(\\mathrm{y - X\\theta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8a465",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D3D3D3; padding:10px;\">\n",
    "    <span style=\"color: red\"><strong>CAUTION_</strong></span>이 공식은 매 경사 하강법 스텝에서 전체 훈련 세트 $\\mathrm{X}$에 대해 계산한다. 그래서 이 알고리즘을 <b>배치 경사 하강법</b><sup>batch gradient descent</sup>이라고 한다. 즉, 매 스텝에서 훈련 데이터 전체를 사용한다(사실 전체 경사 하강법<sup>full gradient descent</sup>이 더 적절한 이름 같다). 이런 이유로 매우 큰 훈련 세트에서는 아주 느리다. 그러나 경사 하강법은 특성 수에 민감하지 않다. 수십만 개의 특성에서 선형 회귀를 훈련시키려면 정규방정식이나 SVD 분해보다 경사 하강법을 사용하는 편이 훨씬 빠르다.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d8bbb",
   "metadata": {},
   "source": [
    "위로 향하는 그레디언트 벡터가 구해지면 반대 방향인 아래로 가야 한다. $\\theta$에서 $\\triangledown_\\theta\\text{MSE}(\\theta)$를 빼야 한다는 뜻이다. 내려가는 스텝의 크기를 결정하기 위해 그레디언트 벡터에 학습률 $\\eta$를 곱한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a84bf3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta^{\\text{next step}} = \\theta - \\eta\\triangledown_\\theta\\text{MSE}(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79232e95",
   "metadata": {},
   "source": [
    "지금까지 정리한 수식과 절차를 이용해 경사 하강법을 파이썬 코드로 구현해 보겠다. 간단한 회귀식인 $y = 4X + 6$을 근사하기 위한 100개의 데이터 세트를 만들고, 여기에 경사 하강법을 이용해 회귀계수 $\\theta_1, \\theta_0$을 도출하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb0e4108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:24:39.712964Z",
     "start_time": "2023-01-23T13:24:39.586728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "# y = 4X + 6을 근사(theta_1=4, theta_0=6). 임의의 값은 노이즈를 위해 만듦.\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 * X + 6 + np.random.randn(100, 1)\n",
    "\n",
    "# X, y 데이터 세트 산점도로 시각화\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611c7d9",
   "metadata": {},
   "source": [
    "데이터는 $y = 4X + 6$을 중심으로 무작위로 퍼져 있다. 다음으로 비용 함수를 정의해 보겠다. 비용 함수 <code>get_cost()</code>는 실제 y 값과 예측된 y 값을 인자로 받아서 $\\frac{1}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})^2$을 계산해 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09084abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:27:25.642044Z",
     "start_time": "2023-01-23T13:27:25.635969Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cost(y, y_pred):\n",
    "    N = len(y)\n",
    "    cost = np.sum(np.square(y - y_pred)) / N\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017d95d",
   "metadata": {},
   "source": [
    "이제 경사 하강법을 <code>gradient_descent()</code>라는 함수를 생성해 구현해 보겠다. <code>gradient_descent()</code>는 $\\theta_1$과 $\\theta_0$을 모두 0으로 초기화한 뒤 iters 개수만큼 반복하면서 $\\theta_1$과 $\\theta_0$을 업데이트한다. 즉, $\\text{새로운} \\theta_1 = \\text{이전} \\theta_1 + \\eta\\frac{2}{n}\\sum_{i=1}^n x^{(i)}(\\text{실제값}^{(i)} - \\text{예측값}^{(i)}),\\\\ \\text{새로운}\\theta_0 = \\text{이전}\\theta_0 + \\eta\\frac{2}{n}\\sum_{i=1}^n(\\text{실제값}^{(i)} - \\text{예측값}^{(i)})$을 반복적으로 적용하면서 $\\theta_1$과 $\\theta_0$을 업데이트하는 것이다. <code>gradient_descent()</code>는 위에서 무작위로 생성한 X와 y를 입력받는데, X와 y 모두 넘파이 ndarray이다. 넘파이 행렬에 $\\theta$를 업데이트하려면 약간의 선형 대수 지식이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6ddb5",
   "metadata": {},
   "source": [
    "여기서 회귀계수 벡터, 가중치 벡터를 지금까진 $\\theta$로 사용했으나 코드에서는 편의상 w로 대체하겠다. 즉, $\\theta_1$은 $w_1$, $\\theta_0$은 $w_0$과 같다고 생각하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b66d63",
   "metadata": {},
   "source": [
    "<code>get_weight_update()</code> 함수에서, 입력 배열 X값에 대한 예측 배열 y_pred는 <code>np.dot(X, w1.T) + w0</code>으로 구한다. 이는 넘파이의 내적 연산을 이용한 것이다. 또한 w1_update로 $-\\eta\\frac{2}{n}\\sum_{i=1}^nx_i\\cdot(\\text{예측 오류}^{(i)})$를, w0_update로 $-\\eta\\frac{2}{n}\\sum_{i=1}^n(\\text{예측 오류}^{(i)})$ 값을 넘파이의 <code>dot</code> 행렬 연산으로 계산한 뒤 이를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "720e9620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:39:28.660728Z",
     "start_time": "2023-01-23T13:39:28.650121Z"
    }
   },
   "outputs": [],
   "source": [
    "# w1과 w0를 업데이트할 w1_update, w0_update를 반환.\n",
    "def get_weight_updates(w1, w0, X, y, learning_rate=0.01):\n",
    "    N = len(y)\n",
    "    # 먼저 w1_update, w0_update를 각각 w1, w0의 shape와 동일한 크기를 가진 0 값으로 초기화\n",
    "    w1_update = np.zeros_like(w1)\n",
    "    w0_update = np.zeros_like(w0)\n",
    "    # 예측 배열 계산하고 예측과 실제 값의 차이 계산\n",
    "    y_pred = np.dot(X, w1.T) + w0\n",
    "    diff = y - y_pred\n",
    "    \n",
    "    # w0_update를 dot 행렬 연산으로 구하기 위해 모두 1값을 가진 행렬 생성\n",
    "    w0_factors = np.ones((N, 1))\n",
    "    # w1과 w0을 업데이트할 w1_update와 w0_update 계산\n",
    "    w1_update = -(2/N) * learning_rate * (np.dot(X.T, diff))\n",
    "    w0_update = -(2/N) * learning_rate * (np.dot(w0_factors.T, diff))\n",
    "    \n",
    "    return w1_update, w0_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9ccb0",
   "metadata": {},
   "source": [
    "다음은 <code>get_weight_updates()</code>을 경사 하강 방식으로 반복적으로 수행하여 w1과 w0를 업데이트하는 함수인 <code>gradient_descent_steps()</code> 함수를 생성하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "205c7df6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:45:45.180797Z",
     "start_time": "2023-01-23T13:45:45.172198Z"
    }
   },
   "outputs": [],
   "source": [
    "# 입력 인자 iters로 주어진 횟수만큼 반복적으로 w1과 w0를 업데이트 적용함.\n",
    "def gradient_descent_steps(X, y, iters=10000):\n",
    "    # w0와 w1을 모두 0으로 초기화.\n",
    "    w0 = np.zeros((1, 1))\n",
    "    w1 = np.zeros((1, 1))\n",
    "    \n",
    "    # 인자로 주어딘 iters 만큼 반복적으로 get_weight_updates() 호출해 w1, w0 업데이트 수행.\n",
    "    for ind in range(iters):\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, X, y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "        \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba97285",
   "metadata": {},
   "source": [
    "이제 <code>gradient_descent_steps()</code>를 호출해 w1과 w0을 구해보겠다. 그리고 최종적으로 예측값과 실제값의 MSE 차이를 계산하는 <code>get_cost()</code> 함수를 호출해 경사 하강법의 예측 오류도 계산해 보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "436cb31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:47:46.269128Z",
     "start_time": "2023-01-23T13:47:46.233968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:4.022 w0:6.162\n",
      "Gradient Descent Total Cost:0.9935\n"
     ]
    }
   ],
   "source": [
    "w1, w0 = gradient_descent_steps(X, y, iters=1000)\n",
    "print(\"w1:{0:.3f} w0:{1:.3f}\".format(w1[0, 0], w0[0, 0]))\n",
    "y_pred = w1[0, 0] * X + w0\n",
    "print('Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949afb3",
   "metadata": {},
   "source": [
    "실제 선형식인 $y = 4X + 6$과 유사하게 w1은 4.022, w0는 6.162가 도출되었다. 예측 오류 비용은 약 0.9935이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2ce7b",
   "metadata": {},
   "source": [
    "앞에서 구한 y_pred에 기반해 회귀선을 그려 보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf7f957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:48:50.629681Z",
     "start_time": "2023-01-23T13:48:50.514175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aebe073d30>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865ec9c",
   "metadata": {},
   "source": [
    "# 미주"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd2b9b",
   "metadata": {},
   "source": [
    "<b id=\"p01\">1</b> 편의상 벡터 표현으로 모델 파라미터와 특성을 모두 표현하기 위해 편향 $\\theta_0$에 가상의 특성 $x_0=1$이 곱해졌다고 생각한다. [↩](#a01)\n",
    "\n",
    "<b id=\"p02\">2</b> 최종 모델을 평가하는 데 사용하는 성능 측정 지표 말고 학습 알고리즘이 다른 함수를 최적화하는 경우가 종종 있다. 일반적으로 성능 측정 지표에는 없는 유용한 미분 특성이 있어서 이런 함수가 계산하기 더 쉽거나, 훈련하는 동안 모델에 제약을 가하기 위해 사용한다. [↩](#a02)\n",
    "\n",
    "<b id=\"p03\">3</b> 사이킷런은 특성의 가중치(coef_)와 편향(intercept_)을 분리하여 저장한다. [↩](#a03)\n",
    "\n",
    "<b id=\"p04\">4</b> $\\mathrm{X}$를 (샘플 수, 특성 수)인 $n\\times m$ 행렬이라 할 때 $\\mathrm{X^TX}$는 $(m\\times n)\\times(n \\times m)=(m\\times m)$ 크기의 행렬이 되므로 샘플 수($n$)가 역행렬 계산의 복잡도를 증가시키지 않고 점곱의 양만 선형적으로 증가시킨다. [↩](#a04)\n",
    "\n",
    "<b id=\"p05\">5</b> 두 점을 이은 선분이 두 점사이에서 항상 곡선 위에 위치할 경우를 볼록 함수, 아래에 위치할 경우 오목 함수라고 한다. [↩](#a05)\n",
    "\n",
    "<b id=\"p06\">6</b> 기술적으로 말하면 이 함수의 도함수가 <b>립시츠 연속</b><sup>Lipschitz continuous</sup>이다. 어떤 함수의 도함수가 일정한 범위 안에서 변할 때 이 함수를 립시츠 연속 함수라고 한다. 예를 들어 $\\text{sin}(x)$는 립시츠 연속 함수지만 $\\sqrt{x}$는 $x=0$일 때 기울기가 무한대가 되므로 립시츠 연속 함수가 아니다. MSE는 $x$가 무한대일 때 기울기가 무한대가 되므로 국부적인(locally) 립시츠 함수라고 한다. [↩](#a06)\n",
    "\n",
    "<b id=\"p07\">7</b> 특성 1이 더 작기 때문에 비용 함수에 영향을 주기 위해서는 $\\theta_1$이 더 크게 바뀌어야 한다. 그래서 $\\theta_1$ 축을 따라서 길쭉한 모양이 된다. 이 그래프에서 비용 함수가 지면에 수직인 축이라고 생각하면 3차원 볼록 함수의 그릇 모양을 이해하기 쉽다. [↩](#a07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eda8c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
