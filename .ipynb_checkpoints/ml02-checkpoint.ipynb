{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e908d",
   "metadata": {},
   "source": [
    "# 머신러닝의 주요 도전 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9a924",
   "metadata": {},
   "source": [
    "간단하게 말해 우리의 주요 작업은 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는 것이므로 문제가 될 수 있는 두 가지는 '나쁜 알고리즘'과 '나쁜 데이터'이다. 이 절에서는 이 두 가지에 대해 알아보고자 한다. 우선 나쁜 데이터의 사례부터 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9ee28",
   "metadata": {},
   "source": [
    "## 충분하지 않은 양의 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e76f1",
   "metadata": {},
   "source": [
    "어린아이에게 사과에 대해 알려주려면 사과를 가리키면서 '사과'라고 말하기만 하면 된다(아마도 이 과정을 여러 번 반복해야 한다). 그러면 아이는 색상과 모양이 달라도 모든 종류의 사과를 구분할 수 있다. 정말 똑똑하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bbe49",
   "metadata": {},
   "source": [
    "머신러닝은 아직 이렇게까지 못한다. 대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다. 아주 간단한 문제에서조차도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개가 필요할지도 모른다(이미 만들어진 모델을 재사용할 수 없다면 말이다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb03686",
   "metadata": {},
   "source": [
    "<center><strong>믿을 수 없는 데이터의 효과</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a7f47",
   "metadata": {},
   "source": [
    "2011년에 발표한 유명한 논문(<a href='https://dl.acm.org/doi/10.3115/1073012.1073017' target='blank'>https://dl.acm.org/doi/10.3115/1073012.1073017</a>)에서 마이크로소프트 연구자인 미셸 반코<sup>Michele Banko</sup>와 에릭 브릴<sup>Eric Brill</sup>은 아주 간단한 모델을 포함하여 여러 다른 머신러닝 알고리즘에 충분한 데이터가 주어지면 복잡한 자연어 중의성 해소<sup>disambiguation[1](#p01)</sup> 문제를 거의 비슷하게 잘 처리한다는 것을 보였다([그림 1-1]에서 볼 수 있다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5570ffb",
   "metadata": {},
   "source": [
    "이 논문의 저자들이 말한 것처럼 이 결과가 제시하는 것은 시간과 돈을 알고리즘 개발에 쓰는 것과 말뭉치<sup>corpus</sup> 개발에 쓰는 것 사이의 트레이드오프에 대해 다시 생각해봐야 한다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f6c17",
   "metadata": {},
   "source": [
    "복잡한 문제에서 알고리즘보다 데이터가 더 중요하다는 이 생각은 2009년 피터 노르빅<sup>Peter Norvig</sup> 등이 쓴 「The Unreasonable Effectiveness of Data」<sup>[2](#p02)</sup> 논문 때문에 더 유명해졌다. 하지만 기억할 점은 작거나 중간 규모의 데이터셋이 여전히 매우 흔하고, 훈련 데이터를 추가로 모으는 것이 항상 쉽거나 저렴한 일은 아니므로, 아직은 알고리즘을 무시하지 말아야 한다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7051e",
   "metadata": {},
   "source": [
    "<strong>그림 1-20</strong> 알고리즘 대비 데이터의 중요성[3](#p03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb568d9",
   "metadata": {},
   "source": [
    "## 대표성 없는 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5d1ad",
   "metadata": {},
   "source": [
    "일반화가 잘되려면 우리가 일반화화기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다. 이는 사례 기반 학습이나 모델 기반 학습 모두 마찬가지이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc6258",
   "metadata": {},
   "source": [
    "예를 들어 앞서 선형 모델을 훈련시키기 위해 사용한 나라의 집합에는 일부 나라가 빠져 있어 대표성이 완벽하지 않다. [그림 1-2]는 누락된 나라를 추가했을 때 데이터가 어떻게 나타나는지 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabab67",
   "metadata": {},
   "source": [
    "이 데이터에 선형 모델을 훈련시키면 실선으로 된 모델을 얻는다. 반면 이전 모델은 점선으로 나타나 있다. 그림에서 알 수 있듯이 누락된 나라를 추가하면 모델이 크게 변경될 뿐만 아니라 이런 간단한 선형 모델은 잘 작동하지 않는다는 걸 확실히 보여준다. 매우 부유한 나라가 중간 정도의 나라보다 행복하지 않고 (실제로도 더 행복해보이지 않다). 반대로 일부 가난한 나라가 부유한 나라보다 행복한 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd95a3",
   "metadata": {},
   "source": [
    "<strong>그림 1-2</strong> 대표성이 더 큰 훈련 샘플\n",
    "<img src=\"images/fundamentals/representative_training_data_scatterplot.png\" alt=\"대표성이 더 큰 훈련 샘플\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edf0de",
   "metadata": {},
   "source": [
    "대표성 없는 훈련 데이터를 사용했으므로 정확한 예측을 하지 못하는, 특히 매우 가난하거나 부유한 나라에서 잘못 예측하는 모델을 훈련시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddccb1ac",
   "metadata": {},
   "source": [
    "일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만, 아게 생각보다 어려울 때가 많다. 샘플이 작으면 <strong>샘플링 잡음</strong><sup>sampling noise</sup>(즉, 우연에 의한 대표성 없는 데이터)이 생기고, 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있다. 이를 <strong>샘플링 편향</strong><sup>sampling bias</sup>이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73475af",
   "metadata": {},
   "source": [
    "<center><strong>유명한 샘플링 편향 사례</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dceb25",
   "metadata": {},
   "source": [
    "아마도 샘플링 편향에 대한 가장 유명한 사례는 랜던<sup>Randon</sup>과 루즈벨트<sup>Roosevelt</sup>가 경쟁했던 1936년 미국 대통령 선거에서 『The Literary Digest』잡지사가 천만 명에게 우편물을 보내 수행한 대규모 여론조사일 것이다. 240만 명의 응답을 받았고 랜던이 선거에서 57% 득표를 얻을 것이라고 높은 신뢰도로 예측했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515f1b0",
   "metadata": {},
   "source": [
    "하지만 루즈벨트가 62% 득표로 당선되었다. 문제는 『The Literary Digest』의 샘플링 방법에 있었다.\n",
    "- 첫째, 여론조사용 주소를 얻기 위해 전화번호부, 자사의 구독자 명부, 클럽 회원 명부 등을 사용했다. 이런 명부는 모두 공화당(랜던)에 투표할 가능성이 높은 부유한 계층에 편중된 경향이 있다.\n",
    "- 둘째, 우편물 수신자 중 25% 미만의 사람이 응답했다. 이는 정치에 관심 없는 사람, 『The Literary Digest』를 싫어하는 사람과 다른 중요한 그룹을 제외시킴으로써 역시 표본을 편향되게 만들었다. 특히 이러한 종류의 샘플링 편향을 <strong>비응답 편항</strong><sup>nonresponse bias</sup>이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd5ff7",
   "metadata": {},
   "source": [
    "다른 예로 펑크 음악 비디오를 분류하는 시스템을 만든다고 가정하자. 이를 위한 훈련 세트를 유튜브에서 '펑크 음악'을 검색해 마련할 수 있다. 하지만 이는 유튜브 검색 엔진이 결괏값으로 유튜브 내의 모든 펑크 음악을 대표하는 동영상을 반환한다고 가정하는 것이다. 현실에서는 검색 결과가 인기 음악가들로 편중될 가능성이 크다(브라질에 살고 있다면 '펑크 음악의 아버지' 제임스 브라운<sup>James Brown</sup>과 전혀 상관없는 '펑크 카리오카<sup>funk caroica</sup>' 동영상을 결과로 보게 될 것이다). 그렇다면 어떻게 대량의 훈련 세트를 구할 수 있을까?<sup>[4](#p04)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97670a5e",
   "metadata": {},
   "source": [
    "## 낮은 품질의 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb039b0",
   "metadata": {},
   "source": [
    "훈련 데이터가 에러, 이상치<sup>outlier</sup>, 잡음(예를 들면 성능이 낮은 측정 장치 때문에)으로 가득하면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다. 따라서 훈련 데이터 정제에 시간을 투자할 만한 가치는 충분하다. 사실 대부분의 데이터 과학자가 데이터 정제에 많은 시간을 쓰고 있다. 다음은 훈련 데이터 정제가 필요한 경우이다.\n",
    "- 일부 샘플이 이상치라는 게 명확하면 간단히 그것들을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋다.\n",
    "- 일부 샘플에 특성 몇 개가 빠져있다면(예를 들면 고객 중 5%가 나이를 기록하지 않음), 이 특성을 모두 무시할지, 이 샘플을 무시할지, 빠진 값을 채울지(예를 들면 평균 나이로), 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181145c",
   "metadata": {},
   "source": [
    "## 관련 없는 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386c524",
   "metadata": {},
   "source": [
    "속담에도 있듯이 엉터리가 들어가면 엉터리가 나온다<sup>garbage in, garbage out</sup>. 훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 효과적으로 학습할 수 있을 것이다. 성공적인 머신러닝 프로젝터의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것이다. 이 과정을 <strong>특정 공학</strong><sup>feature engineering</sup>이라 하며 다음과 같은 작업이다.\n",
    "- <strong>특성 성택</strong><sup>feature selection</sup>: 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.\n",
    "- <strong>특성 추출</strong><sup>feature extraction</sup>: 특성을 결합하여 더 유용한 특성을 만든다. 앞서 본 것처럼 차원 축소 알고리즘이 도움이 될 수 있다.\n",
    "- 새로운 데이터를 수집해 새 특성을 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12474daf",
   "metadata": {},
   "source": [
    "지금까지 나쁜 데이터의 사례를 살펴보았고 이제 나쁜 알고리즘의 예를 몇 가지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c959e43",
   "metadata": {},
   "source": [
    "## 훈련 데이터 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6a7a8",
   "metadata": {},
   "source": [
    "해외여행 중 택시운전사가 내 물건을 훔쳤다고 가정하자. 아마도 그 나라의 <strong>모든</strong> 택시운전사를 도둑이라고 생각할 수도 있다. 사람은 종종 과도하게 일반화를 하지만 주의하지 않으면 기계도 똑같은 함정에 빠질 수 있다. 머신러닝에서는 이를 <strong>과대적합</strong><sup>overfitting</sup>이라고 한다. 이는 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다는 뜻이다. 즉 모델 분산이 커지고, 편향이 낮아져서 관측 데이터는 정확히 예측하지만 새로운 데이터는 정확히 예측하지 못한다. 구체적인 예로 분류 문제에서 훈련 세트의 정확도가 99%이고 검증 세트의 정확도가 80% 수준이라면 과대적합을 의심할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb08d3b",
   "metadata": {},
   "source": [
    "과대적합이 등장하는 이유는 수치계산 분야에서 Runge 현상<sup>Runge's phenomenon</sup>이 발생되기 때문이다. 이것은 어느 측정점을 다항식 함수로 보간<sup>interpolation, fitting</sup>할 때 차수가 너무 높으면, 측정점 사이에서 크게 진동하는 현상을 말한다. 이 원인으로서는 보간하는 알고리즘이 차수에 해당하는 고차의 미분계수를 이용하기 때문에 이 계수가 너무 커서 진동을 야기하는 것이 알려져 있다. 비유를 하여 설명하자면, 10<i>x</i><sup>4</sup>의 계수는 10, 이 식의 3차 미분의 계수는 10 × 4 × 3 × 2 ＝ 240으로 24배가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2348e",
   "metadata": {},
   "source": [
    "오버피팅 현상은 패턴 인식, 머신러닝 등에서 동적이지 않은 경우를 대상으로 할 때에 생긴다. 한편, 시계열 데이터에 대한 ARMA 모델에서는 아무리 차수가 높아도 생기지 않는다. 그 이유는 매개변수 추정 알고리즘에 고차의 미분계수를 사용하는 것이 거의 없기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4eda75",
   "metadata": {},
   "source": [
    "[그림 1-3]은 고차원의 다항 회귀 모델이 삶의 만족도 훈련 데이터에 크게 과대적합된 사례를 보여준다. 간단한 선형 모델보다 이 모델이 훈련 데이터에 더 잘맞는다 하더라도 실제로 이 예측을 믿기는 힘들다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531d097",
   "metadata": {},
   "source": [
    "<strong>그림 1-3</strong> 훈련 데이터에 과대적합\n",
    "<img src=\"images/fundamentals/overfitting_model_plot.png\" alt=\"훈련 데이터에 과대적합\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a85264",
   "metadata": {},
   "source": [
    "심층 신경망 같은 복잡한 모델은 데이터에서 미묘한 패턴을 감지할 수 있지만, 훈련 세트에 잡음이 많거나 데이터셋이 너무 작으면 (샘플링 잡음이 발생하므로) 잡음이 섞인 패턴을 감지하게 된다. 당연히 이런 패턴은 새로운 샘플에 일반화되지 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8cbc3",
   "metadata": {},
   "source": [
    "<strong>CAUTION_</strong>과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다. 해결 방법은 다음과 같다.\n",
    "- 파라미터 수가 적은 모델을 선택하거나(예를 들면 고차원 다항 모델보다 선형 모델), 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킨다.\n",
    "- 훈련 데이터를 더 많이 모은다.\n",
    "- 훈련 데이터의 잡음을 줄인다(예를 들면 오류 데이터 수정과 이상치 제거)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74189edd",
   "metadata": {},
   "source": [
    "모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 <strong>규제</strong><sup>regularization</sup>라고 한다. 예를 들어 앞서 만든 선형 모델은 두 개의 모델 파라미터 <i>θ<sub>0</sup></i>와 <i>θ<sub>1</sup></i>을 가지고 있다. 이는 훈련 데이터에 모델을 맞추기 위한 두 개의 <strong>자유도</strong><sup>degree of free</sup>를 학습 알고리즘에 부여한다. 모델은 직선의 절편(<i>θ<sub>0</sup></i>)과 기울기(<i>θ<sub>1</sup></i>)를 조절할 수 있다. 우리가 <i>θ<sub>1</sup></i> = 0이 되도록 강제하면 알고리즘에 한 개의 자유도만 남게 되고 데이터에 적절하게 맞춰지기 힘들 것이다. 즉, 할 수 있는 것이 훈련 데이터에 가능한 한 가까워지도록 직선을 올리거나 내리는 것이 전부이므로 결국 평균 근처가 된다. 진짜 아주 간단한 모델이다! 알고리즘이 <i>θ<sub>1</sup></i>을 수정하도록 허락하되 작은 값을 갖도록 유지시키면 학습 알고리즘이 자유도 1과 2 사이의 적절한 어딘가에 위치할 것이다. 이는 자유도 2인 모델보다는 단순하고 자유도 1인 모델보다는 복잡한 모델을 만든다. 데이터에 완벽히 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29573df5",
   "metadata": {},
   "source": [
    "[그림 1-4]에 세 가지 모델이 있다. 점선은 (사각형으로 표현된 나라는 제외하고) 동그라미로 표현된 나라로 훈련한 원래 모델이다. 파선은 모든 나라(동그라미와 사각형)를 포함해 훈련한 두 번째 모델이며 실선은 첫 번째 모델과 같은 데이터에 규제를 적용해 만든 선형 모델이다. 규제가 모델의 기울기를 더 작게 만들었다. 이 모델은 훈련 데이터(동그라미)에는 덜 맞지만 훈련하는 동안 못 본 새로운 샘플(사각형)에는 더 잘 일반화된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55375486",
   "metadata": {},
   "source": [
    "<strong>그림 1-4</strong> 규제는 과대적합의 위험을 감소시킨다\n",
    "<img src=\"images/fundamentals/ridge_model_plot.png\" alt=\"규제는 과대적합의 위험을 감소시킨다\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac6a40",
   "metadata": {},
   "source": [
    "학습하는 동안 적용할 규제의 양은 <strong>하이퍼파라미터</strong><sup>hyperparameter</sup>가 결정한다. 하이퍼파라미터는 (모델이 아니라) 학습 알고리즘의 파라미터다. 그래서 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있다. 규제 하이퍼파라미터를 매우 큰 값으로 지정하면 (기울기가 0에 가까운) 거의 평편한 모델을 얻게 된다. 그러면 학습 알고리즘이 훈련 데이터에 과대적합될 가능성은 거의 없겠지만 좋은 모델을 찾지 못한다. 머신러닝 시스템을 구축할 때 하이퍼파라미터 튜닝은 매우 중요한 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0e0f5",
   "metadata": {},
   "source": [
    "<a name='p01'>1</a> 예를 들어 문맥에 따라 'to', 'two', 'too'중 어떤 것을 써야 할지 아는 것\n",
    "\n",
    "<a name='p02'>2</a> Peter Norvig et al., \"The Unreasonable Effectiveness of Data,\" IEEE Intelligent Systems 24, no. 2 (2009): 8-12.\n",
    "\n",
    "<a name='p03'>3</a> 이 그림에서 윈나우(Winnow) 알고리즘은 퍼셉트론(perceptron)과 비슷한 선형 분류 알고리즘으로, 가중치 혹은 모델 파라미터를 변경할 때 덧셈이 아니라 곱셈, 즉 일정한 배수로 이루어진다.\n",
    "\n",
    "<a name='p04'>4</a> 음악 분류를 위한 데이터셋으로는 161개의 장르에 걸쳐 106,574개의 노래를 샘플링한 FMA 데이터셋이 대표적이다. 이 데이터셋에 대한 자세한 내용은 FMA 깃허브(<a href='https://github.com/mdeff/fma' target='blank'>https://github.com/mdeff/fma</a>)를 참고하면 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
