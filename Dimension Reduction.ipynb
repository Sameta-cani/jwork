{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf394062",
   "metadata": {},
   "source": [
    "# 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c297ef2",
   "metadata": {},
   "source": [
    "많은 경우 머신러닝 문제는 훈련 샘플 각각이 수천 심지어 수백만 개의 특성을 가지고 있다. 이런 많은 특성은 훈련을 느리게 할 뿐만 아니라, 앞으로 보게 되겠지만 좋은 솔루션을 찾기 어렵게 만든다. 이런 문제를 종종 <b>차원의 저주</b><sup>curse of dimensionality</sup>라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0329d",
   "metadata": {},
   "source": [
    "다행히도 실전 문제에서는 특성 수를 크게 줄여서 불가능한 문제를 가능한 범위로 변경할 수 있는 경우가 많다. 예를 들어 MNIST 이미지를 생각해보자. 이미지 경계에 있는 픽셀은 거의 항상 흰색이므로 훈련 세트에서 이런 픽셀을 완전히 제거해도 많은 정보를 잃지 않다. 이런 픽셀들은 분류 문제에 크게 중요하지 않다. 게다가 인접한 두 픽셀은 종종 많이 연관되어 있다. 두 픽셀을 하나의 픽셀로 합치더라도(예를 들어 두 픽셀 강도를 평균 냄으로써) 잃는 정보가 많지 않을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431ca01",
   "metadata": {},
   "source": [
    "일반적으로 차원이 증가할수록 데이터 포인트 간의 거리가 기하급수적으로 멀어지게 되고, 희소<sup>sparse</sup>한 구조를 가지게 된다. 수백 개 이상의 피처로 구성된 데이터 세트의 경우 상대적으로 적은 차원에서 학습된 모델보다 에측 신뢰도가 떨어진다. 또한 피처가 많을 경우 개별 피처 간에 상관관계가 높을 가능성이 크다. 선형 회귀와 같은 선형 모델에서는 입력 변수 간의 상관관계가 높을 경우 이로 인한 다중 공선성 문제로 모델의 예측 성능이 저하된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4149935",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D3D3D3; padding:10px;\">\n",
    "    <span style=\"color: red\"><strong>CAUTION_</strong></span>차원을 축소시키면 일부 정보가 유실된다(JPEG로 이미지를 압축하면 품질이 감소되는 것처럼). 그래서 훈련 속도가 빨라질 수는 있지만 시스템의 성능이 조금 나빠질 수 있다. 또한 작업 파이프라인이 조금 더 복잡하게 되고 유지 관리가 어려워진다. 그러므로 차원 축소를 고려하기 전에 훈련이 너무 느린지 먼저 원본 데이터로 시스템을 훈련해봐야 한다. 어떤 경우에는 훈련 데이터의 차원을 축소시키면 잡음이나 불필요한 세부사항을 걸러내므로 성능을 높일 수 있다. 일반적으로는 훈련 속도만 빨라진다.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b32e4",
   "metadata": {},
   "source": [
    "훈련 속도를 높이는 것 외에 차원 축소는 데이터 시각화<sup>data visualization</sup>(또는 DataViz)에도 아주 유용하다. 차원 수를 둘로(또는 셋으로) 줄이면 고차원 훈련 세트를 하나의 압축된 그래프로 그릴 수 있고 군집 같은 시각적인 패턴을 감지해 중요한 통찰을 얻는 경우가 많다. 또한 데이터 과학자가 아닌 사람들, 특히 최종 결과를 사용하는 결정권자에게 비지니스적인 판단을 설명하는데 데이터 시각화는 필수적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa16834",
   "metadata": {},
   "source": [
    "일반적으로 차원 축소는 피처 선택<sup>feature selection</sup>과 피처 추출<sup>feature extraction</sup>로 나눌 수 있다. <u>피처 선택, 즉 특성 선택은 말 그대로 특정 피처에 종속성이 강한 불필요한 피처는 아예 제거하고, 데이터의 특징을 잘 나타내는 주요 피처만 선택하는 것이다. 피처(특성) 추출은 기존 피처를 저차원의 중요 피처로 압축해서 추출하는 것이다. 이렇게 새롭게 추출된 중요 특성은 기존의 피처가 압축된 것이므로 기존의 피처와는 완전히 다른 값이 된다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213447a6",
   "metadata": {},
   "source": [
    "<u>피처 추출은 기존 피처를 단순 압축이 아닌, 피처를 함축적으로 더 잘 설명할 수 있는 또 다른 공간으로 매핑해 추출하는 것이다.</u> 가령 학생을 평가하는 다양한 요소로 모의고사 성적, 종합 내신성적, 수능성적, 봉사활동, 대외활동, 학교 내외 수상경력 등과 관련된 여러 가지 피처로 돼 있는 데이터 세트라면 이를 학업 성취도, 커뮤니케이션 능력, 문제 해결력과 같은 더 함축적인 요약 특성으로 추출할 수 있다. 이러한 함축적인 특성 추출은 기존 피처가 전혀 인지하기 어려웠던 잠재적인 요소<sup>Latent Factor</sup>를 추츨하는 것을 의미한다(위의 학생 평가 요소는 사실 함축적인 의미를 인지하기 어려운 것은 아니다. 함축성의 의미가 무엇인지 예를 든 것일 뿐이다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255601a",
   "metadata": {},
   "source": [
    "이처럼 <u>차원 축소는 단순히 데이터의 압축을 의미하는 것이 아니다. 더 중요한 의미는 차원 축소를 통해 좀 더 데이터를 잘 설명할 수 있는 잠재적인 요소를 추출하는 데에 있다.</u> PCA, SVD, NMF는 이처럼 잠재적인 요소를 찾는 대표적인 차원 축소 알고리즘이다. 매우 많은 차원을 가지고 있는 이미지나 텍스트에서 차원 축소를 통해 잠재적인 의미를 찾아 주는 데 이 알고리즘이 잘 활용되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49885d",
   "metadata": {},
   "source": [
    "이 차원 축소 알고리즘은 매우 많은 픽셀로 이뤄진 이미지 데이터에서 잠재된 특성을 피처로 도출해 함축적 형태의 이미지 변환과 압축을 수행할 수 있다. 이렇게 변환된 이미지는 원본 이미지보다 훨씬 적은 차원이기 때문에 이미지 분류 등의 분류 수행 시에 과대적합<sup>overfitting</sup> 영향력이 작아져서 오히려 원본 데이터로 예측하는 것보다 예측 성능을 더 끌어 올릴 수 있다. 이미지 자체가 가지고 있는 차원의 수가 너무 크기 때문에 비슷한 이미지라도 적은 픽셀의 차이가 잘못된 예측으로 이어질 수 있기 때문이다. 이 경우 함축적으로 차원을 축소하는 것이 예측 성능에 훨씬 도움이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8e2b9",
   "metadata": {},
   "source": [
    "차원 축소 알고리즘이 자주 사용되는 또 다른 영역은 텍스트 문서의 숨겨진 의미를 추출하는 것이다. 문서는 많은 단어로 구성돼 있다. 문서를 만드는 사람은 어떤 의미나 의도를 가지고 문서를 작성하면서 단어를 사용하게 된다. 일반적으로 사람의 경우 문서를 읽으면서 이 문서가 어떤 의미나 의도를 가지고 작성됐는지 쉽게 인지할 수 있다(물론 그렇지 않은 난해한 문서도 있다만). 차원 축소 알고리즘은 문서 내 단어들의 구성에서 숨겨져 있는 시맨틱<sup>Semantic</sup> 의미나 토픽<sup>Topic</sup>을 잠재 요소로 간주하고 이를 찾아낼 수 있다. SVD와 NMF는 이러한 시맨틱 토픽<sup>Semantic Topic</sup> 모델링을 위한 기반 알고리즘으로 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497860b",
   "metadata": {},
   "source": [
    "# 차원의 저주"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e94e1c",
   "metadata": {},
   "source": [
    "우리는 3차원 세계에서 살고 있어서 고차원 공간을 직관적으로 상상하기 어렵다. 1,000차원의 공간에서 휘어져 있는 200차원의 타원체는 고사하고 기본적인 4차원 초입방체<sup>hypercube</sup>조차도 머릿속에 그리기 어렵다(그림 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c250a7",
   "metadata": {},
   "source": [
    "<b>그림 1</b> 점, 선, 정사각형, 정육면체, 테서렉트(0차원에서 4차원까지의 초입방체)\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/dim_red.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d1cd9",
   "metadata": {},
   "source": [
    "고차원 공간에서는 많은 것이 상당히 다르게 작동한다. 예를 들어 단위 면적(1 x 1 사각형) 안에 있는 점을 무작위로 선택한다면 경계선에서 0.001 이내에 위치할 가능성은 0.4%다(다른 말로 하면 어느 방향으로든 거의 끝부분에 있는 점을 선택할 가능성은 매우 낮다).<sup><a id=\"a01\" href=\"#p01\">[1]</a></sup> 하지만 10,000차원의 단위 면적을 가진 초입방체에서는 이 가능성이 99.999999%보다 커진다.<sup><a id=\"a02\" href=\"#p02\">[2]</a></sup> 고차원 초입방체에 있는 대다수의 점은 경계와 매우 가까이 있다.<sup><a id=\"a03\" href=\"#p03\">[3]</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aacfa",
   "metadata": {},
   "source": [
    "여기에 더 심각한 차이점이 있다. 단위 면적에서 임의의 두 점을 선택하면 두 점 사이의 거리는 평균적으로 대략 0.52가 된다. 3차원 큐브에서 임의의 두 점을 선택하면 평균 거리는 대략 0.66이다. 만약 1,000,000차원의 초입방체에서 두 점을 무작위로 선택하면 어떨까? 믿거나 말거나 평균 거리는 약 408.25(대략 $\\sqrt{1,000,000/6}$이다.<sup><a id=\"a04\" href=\"#p04\">[4]</a></sup> 이는 직관적이지 않다. 두 점이 단위 초입방체에 같이 놓여 있는데 어떻게 이렇게 멀리 떨어져 있는 걸까? 고차원은 많은 공간을 가지고 있기 때문이다. 이로 인해 고차원 데이터셋은 매우 희박할 위험이 있다. 즉, 대부분의 훈련 데이터가 서로 멀리 떨어져 있다. 이는 새로운 샘플도 훈련 샘플과 멀리 떨어져 있을 가능성이 높다는 뜻이다. 이 경우 예측을 위해 훨씬 많은 외삽<sup>extrapolation</sup>을 해야 하기 때문에 저차원일 때보다 예측이 더 불안정하다. 간단히 말해 훈련 세트의 차원이 클수록 과대적합 위험이 커진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2c444",
   "metadata": {},
   "source": [
    "이론적으로 차원의 저주를 해결하는 해결책 하나는 훈련 샘플의 밀도가 충분히 높아질 때까지 훈련 세트의 크기를 키우는 것이다. 불행하게도 실제로는 일정 밀도에 도달하기 위해 필요한 훈련 샘플 수는 차원 수가 커짐에 따라 기하급수적으로 늘어난다. 특성 수가 (MNIST 문제보다 훨씬 적은) 단 100개라고 생각해도, 모든 차원에 걸쳐 균일하게 퍼져 있다고 가정하고 훈련 샘플을 서로 평균 0.1 이내에 위치시키려면 관측 가능한 우주에 있는 원자 수 모두를 합친 것보다 더 많은 훈련 샘플을 모아야 한다.<sup><a id=\"a05\" href=\"#p05\">[5]</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f581374",
   "metadata": {},
   "source": [
    "# 차원 축소를 위한 접근 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb01dd",
   "metadata": {},
   "source": [
    "구체적인 차원 축소 알고리즘을 알아보기 전에 차원을 감소시키는 두 가지 주요한 접근법인 투영<sup>projection</sup>과 매니폴드 학습을 살펴보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce017fcb",
   "metadata": {},
   "source": [
    "## 투영"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921794f",
   "metadata": {},
   "source": [
    "대부분의 실전 문제는 훈련 샘플이 모든 차원에 걸쳐 균일하게 퍼져 있지 않다. 많은 특성은 거의 변화가 없는 반면, (앞서 말한 MNIST의 경우처럼) 다른 특성들은 서로 강하게 연관되어 있다. 결과적으로 모든 훈련 샘플이 고차원 공간 안의 저차원 <b>부분 공간</b><sup>subspace</sup>(또는 가까이) 놓여 있다.<sup><a id=\"a06\" href=\"#p06\">[6]</a></sup> 너무 추상적인 말이라 예를 들어 살펴보겠다. [그림 2]에 원 모양을 띤 3차원 데이터셋이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909635d",
   "metadata": {},
   "source": [
    "<b>그림 2</b> 2차원에 가깝게 배치된 3차원 데이터셋\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/3dim.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf081c7",
   "metadata": {},
   "source": [
    "모든 훈련 샘플이 거의 평면 형태로 놓여 있다. 이것이 고차원(3D) 공간에 있는 저차원 (2D) 부분 공간이다. 여기서 모든 훈련 샘플을 이 부분 공간에 수직으로(즉, 샘플과 평면 사이의 가장 짧은 직선을 따라) 투영하면 [그림 3]과 같은 2D 데이터셋을 얻는다. 이는 데이터셋의 차원을 3D에서 2D로 줄인 것이다. 각 축은 (평면에 투영된 좌표인 새로운 특성 $z_1$과 $z_2$에 대응된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fbb901",
   "metadata": {},
   "source": [
    "<b>그림 3</b> 투영하여 만들어진 새로운 2D 데이터셋\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/2dim.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034c389",
   "metadata": {},
   "source": [
    "그러나 차원 축소에 있어서 투영이 언제나 최선의 방법은 아니다. 많은 경우 [그림 4]에 표현된 <b>스위스 롤</b><sup>Swiss roll</sup> 데이터셋처럼 부분 공간이 뒤틀리거나 휘어 있기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e041197",
   "metadata": {},
   "source": [
    "<b>그림 4</b> 스위스 롤 데이터셋\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/Swiss roll.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb693ce",
   "metadata": {},
   "source": [
    "그냥 평면에 투영시키면(예를 들어 $x_3$을 버리고) [그림 5]의 왼쪽처럼 스위스 롤의 층이 서로 뭉개진다. 우리가 원하는 것은 스위스 롤을 펼쳐서 오른쪽처럼 2D 데이터셋을 얻는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004380dd",
   "metadata": {},
   "source": [
    "<b>그림 5</b> 평면에 그냥 투영시켜서 뭉개진 것(왼쪽)과 스위스 롤을 펼쳐놓은 것(오른쪽)\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/Swiss roll red.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9fd99",
   "metadata": {},
   "source": [
    "## 매니폴드 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9b453",
   "metadata": {},
   "source": [
    "스위스 롤은 2D <b>매니폴드</b>의 한 예다. 간단히 말해 2D 매니폴드는 고차원 공간에서 휘어지거나 뒤틀린 2D 모양이다. 더 일반적으로 $d$차원 매니폴드는 국부적으로 $d$차원 초평면으로 보일 수 있는 $n$차원 공간의 일부다($d < n$). 스위스 롤의 경우에는 $d=2$이고 $n=3$이다. 국부적으로는 2D 평면으로 보이지만 3차원으로 말려 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e6ac2",
   "metadata": {},
   "source": [
    "많은 차원 축소 알고리즘이 훈련 샘플이 놓여 있는 <b>매니폴드</b>를 모델링하는 식으로 작동한다. 이를 <b>매니폴드 학습</b><sup>manifold learning</sup>이라고 한다. 이는 대부분 실제 고차원 데이터셋이 더 낮은 저차원 매니폴드에 가깝게 놓여 있다는 <b>매니폴드 가정</b><sup>manifold assumption</sup> 또는 <b>매니폴드 가설</b><sup>manifold hypothesis</sup>에 근거한다. 경험적으로도 이런 가정은 매우 자주 발견된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8f70f",
   "metadata": {},
   "source": [
    "여기에서도 MNIST 데이터셋으로 생각해보겠다. 전체 손글씨 숫자 이미지는 어느 정도 비슷한 면이 있다. 선으로 연결되어 있고 경계는 흰색이고 어느 정도 중앙에 있다. 무작위로 생성된 이미지라면 그중 아주 적은 일부만 손글씨 숫자처럼 보일 것이다. 다시 말해 숫자 이미지를 만들 때 가능한 자유도는 아무 이미지나 생성할 때의 자유도보다 훨씬 낮다. 이런 제약은 데이터셋을 저차원의 매니폴드로 압축할 수 있도록 도와준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a71ed",
   "metadata": {},
   "source": [
    "매니폴드 가정은 종종 암묵적으로 다른 가정과 병행되곤 한다. 바로 처리해야 할 작업(예를 들면 분류나 회귀)이 저차원의 매니폴드 공간에 표현되면 더 간단해질 것이란 가정이다. 예를 들어 [그림 6]의 첫 번째 행에서는 스위스 롤이 두 개의 클래스로 나뉘어 있다. 3D(왼쪽)에서는 결정 경계가 매우 복잡하지만 펼쳐진 매니폴드 공간인 2D(오른쪽)에서는 결정 경계가 단순한 직선이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19941a",
   "metadata": {},
   "source": [
    "그러나 이런 암묵적인 가정이 항상 유효하지는 않다. [그림 6]의 두 번째 행의 경우에는 결정 경계가 $x_1=5$에 놓여 있다. 이 결정 경계는 3D 공간에서는 매우 단순하다(수직 평면). 하지만 펼쳐진 매니폴드에서는 결정 경계가 더 복잡해졌다(네 개의 독립된 수직선)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72f0b7",
   "metadata": {},
   "source": [
    "<b>그림 6</b> 저차원에서 항상 간단하지 않은 결정 경계\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./images/dim_red/manifold.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9214a43",
   "metadata": {},
   "source": [
    "요약하면 모델을 훈련시키기 전에 훈련 세트의 차원을 감소시키면 훈련 속도는 빨라지지만 항상 더 낫거나 간단한 솔루션이 되는 것은 아니다. 이는 전적으로 데이터셋에 달려있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa56671",
   "metadata": {},
   "source": [
    "# 미주"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecf27b",
   "metadata": {},
   "source": [
    "<b id=\"p01\">1</b> 1 x 1 사각형에서 테두리 0.001을 제외한 안쪽 사각형의 면적은 (1 - 0.001 x 2)<sup>2</sup> = 0.996004다. 따라서 두께 0.001인 테두리의 너비는 1 - 0.996004 = 0.003996이므로 단위 면적의 약 0.4%가 된다.\n",
    "\n",
    "<b id=\"p02\">2</b> 테두리를 제외한 초입방체의 부피를 같은 방식으로 계산하면 $(1 - 0.001 \\times 2)^{10000} \\approx 0.000000002$가 되므로 테두리의 공간은 1 - 0.000000002 = 0.999999998이 된다.\n",
    "\n",
    "<b id=\"p03\">3</b> 재미있는 사실: 충분히 많은 차원이 있다는 점을 고려하면 적어도 한 가지 면에서는 극단주의 성향이 있을 가능성이 높다(예를 들면 커피에 넣는 설탕의 양).\n",
    "\n",
    "<b id=\"p04\">4</b> 무작위로 선택한 두 점 사이의 평균 거리는 적분을 이용해 계산한다. 2차원일 때 평균 거리는 $\\frac{1}{15}(\\sqrt2 + 2 + 5ln(1+\\sqrt2))=0.521405$이며 n차원일 때 평균 거리는 최대 $\\sqrt{n}{6}$을 넘지 않는다. 따라서 1,000,000차원 초입방체에서 임의의 두 점 사이의 평균 거리는 대략 $\\sqrt{\\frac{1,000,000}{6}}$이라고 할 수 있다.\n",
    "\n",
    "<b id=\"p05\">5</b> 크기가 1인 2차원 평면에 0.1 거리 이내에 훈련 샘플을 모두 놓으려면 최소한 10 x 10 개의 샘플이 필요하다. 이를 100개의 차원으로 확장하면 10<sup>100</sup>개의 훈련 샘플이 필요하다. 우주에 존재하는 원자 수는 관측 가능한 우주의 질량을 수소 원자의 질량으로 나눠 계산할 수 있는데, 대략 10<sup>80</sup>개로 알려져 있다.\n",
    "\n",
    "<b id=\"p06\">6</b> 거의 모두 흰색인 테두리 부분을 떼어놓고 생각하면 대부분의 이미지가 더 낮은 차원(적은 픽셀)인 부분 공간에 놓여 있다고 말할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
